#!/usr/bin/env python3
"""
æ™ºèƒ½PDFå¤„ç†å™¨
é€šè¿‡ç®€åŒ–çš„å‚æ•°è‡ªåŠ¨å®ŒæˆPDFè§£æâ†’RAGå¤„ç†â†’æ–‡æ¡£ç”Ÿæˆçš„å®Œæ•´æµç¨‹
è®©ä¸»agentèƒ½å¤Ÿé€šè¿‡å•ä¸ªå·¥å…·è°ƒç”¨å®Œæˆæ‰€æœ‰æ“ä½œ
"""

import os
import json
import logging
from typing import Dict, List, Any, Optional
from datetime import datetime

# å¯¼å…¥ç°æœ‰å·¥å…·
from pdf_parser_tool import PDFParserTool
from rag_tool_chroma import RAGTool
from base_tool import Tool

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class IntelligentPDFProcessor(Tool):
    """æ™ºèƒ½PDFå¤„ç†å™¨ - è‡ªåŠ¨åŒ–çš„PDFå¤„ç†å’ŒçŸ¥è¯†åº“æ„å»º"""
    
    def __init__(self):
        super().__init__(
            name="intelligent_pdf_processor",
            description="ğŸ¤– æ™ºèƒ½PDFå¤„ç†å™¨ - è‡ªåŠ¨å®ŒæˆPDFè§£æã€embeddingã€å›¾ç‰‡RAGçš„å®Œæ•´æµç¨‹ã€‚åªéœ€æä¾›PDFè·¯å¾„ï¼Œç³»ç»Ÿè‡ªåŠ¨å¤„ç†æ‰€æœ‰æ­¥éª¤ã€‚"
        )
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.pdf_parser = PDFParserTool()
        self.text_rag = RAGTool()
        self.image_rag = ImageRAGTool()
        
        # æ™ºèƒ½å¤„ç†é…ç½®
        self.auto_config = {
            "auto_embedding": True,        # è‡ªåŠ¨è¿›è¡Œæ–‡æœ¬embedding
            "auto_image_processing": True, # è‡ªåŠ¨è¿›è¡Œå›¾ç‰‡RAG
            "auto_description": True,      # è‡ªåŠ¨ç”Ÿæˆå›¾ç‰‡æè¿°
            "auto_cleanup": True,          # è‡ªåŠ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            "enable_batch_mode": True,     # å¯ç”¨æ‰¹é‡å¤„ç†æ¨¡å¼
            "smart_project_detection": True  # æ™ºèƒ½é¡¹ç›®åç§°æ£€æµ‹
        }
        
        logger.info("âœ… æ™ºèƒ½PDFå¤„ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def execute(self, **kwargs) -> str:
        """
        æ™ºèƒ½PDFå¤„ç† - ä¸»agentåªéœ€è¦æä¾›æœ€åŸºæœ¬çš„å‚æ•°
        
        Args:
            pdf_source: PDFæ–‡ä»¶è·¯å¾„æˆ–ç›®å½•è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
            task_type: ä»»åŠ¡ç±»å‹
                - "knowledge_base": ä»…æ„å»ºçŸ¥è¯†åº“ï¼ˆé»˜è®¤ï¼‰
                - "document_generation": æ„å»ºçŸ¥è¯†åº“å¹¶ç”Ÿæˆæ–‡æ¡£
                - "batch_processing": æ‰¹é‡å¤„ç†
            generation_request: æ–‡æ¡£ç”Ÿæˆè¯·æ±‚ï¼ˆtask_typeä¸ºdocument_generationæ—¶ï¼‰
            project_name: é¡¹ç›®åç§°ï¼ˆå¯é€‰ï¼Œç³»ç»Ÿå¯è‡ªåŠ¨æ£€æµ‹ï¼‰
            output_format: è¾“å‡ºæ ¼å¼ï¼ˆdocx/jsonï¼Œé»˜è®¤docxï¼‰
        
        Returns:
            å®Œæ•´å¤„ç†ç»“æœçš„JSONå­—ç¬¦ä¸²
        """
        
        # è·å–å‚æ•°
        pdf_source = kwargs.get("pdf_source")
        task_type = kwargs.get("task_type", "knowledge_base")
        generation_request = kwargs.get("generation_request", "")
        project_name = kwargs.get("project_name", "")
        output_format = kwargs.get("output_format", "docx")
        
        if not pdf_source:
            return json.dumps({
                "status": "error",
                "message": "è¯·æä¾›PDFæ–‡ä»¶è·¯å¾„æˆ–ç›®å½•è·¯å¾„ (pdf_sourceå‚æ•°)",
                "usage": "intelligent_pdf_processor(pdf_source='path/to/file.pdf', task_type='knowledge_base')"
            }, indent=2, ensure_ascii=False)
        
        # æ™ºèƒ½ä»»åŠ¡è·¯ç”±
        try:
            if task_type == "knowledge_base":
                return self._build_knowledge_base(pdf_source, project_name)
            elif task_type == "document_generation":
                return self._full_pipeline_with_generation(
                    pdf_source, generation_request, project_name, output_format
                )
            elif task_type == "batch_processing":
                return self._intelligent_batch_processing(pdf_source, project_name)
            else:
                return json.dumps({
                    "status": "error",
                    "message": f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {task_type}",
                    "supported_types": ["knowledge_base", "document_generation", "batch_processing"]
                }, indent=2, ensure_ascii=False)
                
        except Exception as e:
            logger.error(f"æ™ºèƒ½PDFå¤„ç†å¤±è´¥: {e}")
            return json.dumps({
                "status": "error",
                "message": f"å¤„ç†å¤±è´¥: {str(e)}",
                "timestamp": datetime.now().isoformat()
            }, indent=2, ensure_ascii=False)
    
    def _build_knowledge_base(self, pdf_source: str, project_name: str = "") -> str:
        """æ„å»ºçŸ¥è¯†åº“ï¼ˆè‡ªåŠ¨åŒ–PDFå¤„ç†å’ŒRAGï¼‰"""
        
        result = {
            "status": "processing",
            "task_type": "knowledge_base",
            "pdf_source": pdf_source,
            "timestamp": datetime.now().isoformat(),
            "auto_processing_steps": []
        }
        
        try:
            # è‡ªåŠ¨æ£€æµ‹PDFç±»å‹ï¼ˆå•æ–‡ä»¶ vs ç›®å½•ï¼‰
            if os.path.isfile(pdf_source):
                pdf_files = [pdf_source]
                processing_mode = "single_file"
            elif os.path.isdir(pdf_source):
                pdf_files = self._discover_pdf_files(pdf_source)
                processing_mode = "directory"
            else:
                raise Exception(f"PDFæºä¸å­˜åœ¨: {pdf_source}")
            
            result["discovered_files"] = len(pdf_files)
            result["processing_mode"] = processing_mode
            
            if not pdf_files:
                raise Exception("æœªå‘ç°PDFæ–‡ä»¶")
            
            # æ™ºèƒ½é¡¹ç›®åç§°æ£€æµ‹
            if not project_name and self.auto_config["smart_project_detection"]:
                project_name = self._detect_project_name(pdf_source, pdf_files)
                result["auto_detected_project"] = project_name
            
            # å¤„ç†æ¯ä¸ªPDFæ–‡ä»¶
            processed_files = []
            total_texts = 0
            total_images = 0
            
            for pdf_file in pdf_files:
                file_result = self._process_single_pdf_intelligent(pdf_file, project_name)
                processed_files.append(file_result)
                
                if file_result.get("status") == "success":
                    total_texts += file_result.get("text_chunks", 0)
                    total_images += file_result.get("processed_images", 0)
            
            result.update({
                "status": "success",
                "message": f"çŸ¥è¯†åº“æ„å»ºå®Œæˆ: {len(pdf_files)}ä¸ªPDFæ–‡ä»¶",
                "processed_files": processed_files,
                "knowledge_base_stats": {
                    "total_text_chunks": total_texts,
                    "total_images": total_images,
                    "project_name": project_name
                },
                "next_steps": [
                    "å¯ä»¥ä½¿ç”¨ task_type='document_generation' ç”Ÿæˆæ™ºèƒ½æ–‡æ¡£",
                    "æˆ–ç›´æ¥ä½¿ç”¨å·²æ„å»ºçš„çŸ¥è¯†åº“è¿›è¡Œæ£€ç´¢"
                ]
            })
            
            return json.dumps(result, indent=2, ensure_ascii=False)
            
        except Exception as e:
            result.update({
                "status": "error",
                "message": str(e)
            })
            return json.dumps(result, indent=2, ensure_ascii=False)
    
    def _full_pipeline_with_generation(self, pdf_source: str, generation_request: str, 
                                     project_name: str = "", output_format: str = "docx") -> str:
        """å®Œæ•´æµæ°´çº¿ï¼šPDFå¤„ç† + çŸ¥è¯†åº“æ„å»º + æ–‡æ¡£ç”Ÿæˆ"""
        
        result = {
            "status": "processing",
            "task_type": "full_pipeline",
            "pdf_source": pdf_source,
            "generation_request": generation_request,
            "timestamp": datetime.now().isoformat(),
            "pipeline_phases": []
        }
        
        try:
            # é˜¶æ®µ1: æ„å»ºçŸ¥è¯†åº“
            logger.info("ğŸ”„ é˜¶æ®µ1: æ„å»ºçŸ¥è¯†åº“")
            kb_result_str = self._build_knowledge_base(pdf_source, project_name)
            kb_result = json.loads(kb_result_str)
            
            phase1 = {
                "phase": "knowledge_base_building",
                "status": kb_result.get("status"),
                "stats": kb_result.get("knowledge_base_stats", {}),
                "message": kb_result.get("message", "")
            }
            result["pipeline_phases"].append(phase1)
            
            if kb_result.get("status") != "success":
                result["status"] = "failed"
                result["message"] = "çŸ¥è¯†åº“æ„å»ºå¤±è´¥"
                return json.dumps(result, indent=2, ensure_ascii=False)
            
            # ä½¿ç”¨æ£€æµ‹åˆ°çš„é¡¹ç›®åç§°
            if not project_name:
                project_name = kb_result.get("auto_detected_project", "")
            
            # é˜¶æ®µ2: æ™ºèƒ½æ–‡æ¡£ç”Ÿæˆ
            logger.info("ğŸ“ é˜¶æ®µ2: æ™ºèƒ½æ–‡æ¡£ç”Ÿæˆ")
            doc_result = self._generate_intelligent_document(
                generation_request, project_name, output_format
            )
            
            phase2 = {
                "phase": "document_generation",
                "status": doc_result.get("status"),
                "output": doc_result.get("output", {}),
                "message": doc_result.get("message", "")
            }
            result["pipeline_phases"].append(phase2)
            
            # æœ€ç»ˆç»“æœ
            if doc_result.get("status") == "success":
                result.update({
                    "status": "success",
                    "message": "å®Œæ•´æµæ°´çº¿æ‰§è¡ŒæˆåŠŸ",
                    "final_outputs": {
                        "knowledge_base": kb_result.get("knowledge_base_stats"),
                        "generated_document": doc_result.get("output")
                    }
                })
            else:
                result.update({
                    "status": "partial_success", 
                    "message": "çŸ¥è¯†åº“æ„å»ºæˆåŠŸï¼Œæ–‡æ¡£ç”Ÿæˆå¤±è´¥"
                })
            
            return json.dumps(result, indent=2, ensure_ascii=False)
            
        except Exception as e:
            result.update({
                "status": "error",
                "message": str(e)
            })
            return json.dumps(result, indent=2, ensure_ascii=False)
    
    def _process_single_pdf_intelligent(self, pdf_path: str, project_name: str) -> Dict[str, Any]:
        """æ™ºèƒ½å¤„ç†å•ä¸ªPDFæ–‡ä»¶"""
        
        file_result = {
            "pdf_path": pdf_path,
            "filename": os.path.basename(pdf_path),
            "status": "processing",
            "timestamp": datetime.now().isoformat()
        }
        
        try:
            # æ­¥éª¤1: PDFè§£æ
            logger.info(f"ğŸ“„ è§£æPDF: {os.path.basename(pdf_path)}")
            parse_result_str = self.pdf_parser.execute(
                pdf_path=pdf_path,
                action="parse"
            )
            parse_result = json.loads(parse_result_str)
            
            if parse_result.get("status") != "success":
                file_result.update({
                    "status": "failed",
                    "message": "PDFè§£æå¤±è´¥",
                    "error": parse_result.get("message", "")
                })
                return file_result
            
            output_dir = parse_result.get("output_directory")
            content_file = parse_result.get("content_file")
            images_file = parse_result.get("images_file")
            
            # æ­¥éª¤2: è‡ªåŠ¨æ–‡æœ¬embedding
            text_chunks = 0
            if self.auto_config["auto_embedding"] and content_file:
                logger.info("ğŸ§  è‡ªåŠ¨æ–‡æœ¬embedding")
                text_chunks = self._auto_text_embedding(content_file, pdf_path, project_name)
            
            # æ­¥éª¤3: è‡ªåŠ¨å›¾ç‰‡RAGå¤„ç†
            processed_images = 0
            if self.auto_config["auto_image_processing"] and images_file:
                logger.info("ğŸ–¼ï¸ è‡ªåŠ¨å›¾ç‰‡RAGå¤„ç†")
                processed_images = self._auto_image_rag_processing(
                    images_file, output_dir, project_name
                )
            
            # æ­¥éª¤4: è‡ªåŠ¨æ¸…ç†ï¼ˆå¯é€‰ï¼‰
            if self.auto_config["auto_cleanup"]:
                self._cleanup_temporary_files(output_dir, content_file, images_file)
            
            file_result.update({
                "status": "success",
                "message": "PDFæ™ºèƒ½å¤„ç†å®Œæˆ",
                "statistics": parse_result.get("statistics", {}),
                "text_chunks": text_chunks,
                "processed_images": processed_images,
                "output_directory": output_dir
            })
            
            return file_result
            
        except Exception as e:
            file_result.update({
                "status": "error",
                "message": str(e)
            })
            return file_result
    
    def _auto_text_embedding(self, content_file: str, pdf_path: str, project_name: str) -> int:
        """è‡ªåŠ¨æ–‡æœ¬embeddingå¤„ç†"""
        try:
            # è¯»å–è§£æåçš„å†…å®¹
            with open(content_file, 'r', encoding='utf-8') as f:
                content_data = json.load(f)
            
            # æå–å’Œå¤„ç†æ–‡æœ¬
            text_content = self._extract_text_intelligently(content_data)
            
            if not text_content.strip():
                return 0
            
            # åˆ›å»ºä¸´æ—¶æ–‡æœ¬æ–‡ä»¶
            temp_txt_path = content_file.replace('.json', '_processed.txt')
            with open(temp_txt_path, 'w', encoding='utf-8') as f:
                f.write(text_content)
            
            # è‡ªåŠ¨ç”Ÿæˆæ–‡æ¡£æ ‡è¯†
            doc_filename = f"{project_name}_{os.path.basename(pdf_path)}" if project_name else os.path.basename(pdf_path)
            
            # æ‰§è¡ŒRAGå¤„ç†
            rag_result = self.text_rag.execute(
                action="upload",
                file_path=temp_txt_path,
                filename=doc_filename
            )
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if os.path.exists(temp_txt_path):
                os.remove(temp_txt_path)
            
            # ä»ç»“æœä¸­æå–åˆ†å—æ•°é‡
            if "åˆ†å—æ•°é‡" in rag_result:
                import re
                chunks_match = re.search(r'åˆ†å—æ•°é‡:\s*(\d+)', rag_result)
                return int(chunks_match.group(1)) if chunks_match else 1
            
            return 1
            
        except Exception as e:
            logger.warning(f"æ–‡æœ¬embeddingå¤±è´¥: {e}")
            return 0
    
    def _auto_image_rag_processing(self, images_file: str, output_dir: str, project_name: str) -> int:
        """è‡ªåŠ¨å›¾ç‰‡RAGå¤„ç†"""
        try:
            if not os.path.exists(images_file):
                return 0
            
            with open(images_file, 'r', encoding='utf-8') as f:
                images_data = json.load(f)
            
            processed_count = 0
            
            for image_id, image_info in images_data.items():
                try:
                    # æŸ¥æ‰¾å›¾ç‰‡æ–‡ä»¶
                    image_filename = image_info.get("filename", f"{image_id}.png")
                    image_path = os.path.join(output_dir, image_filename)
                    
                    if not os.path.exists(image_path):
                        continue
                    
                    # æ™ºèƒ½ç”Ÿæˆæè¿°
                    description = self._generate_smart_description(
                        image_info, image_filename, project_name
                    )
                    
                    # ä¸Šä¼ åˆ°å›¾ç‰‡RAG
                    upload_result = self.image_rag.execute(
                        action="upload",
                        image_path=image_path,
                        description=description
                    )
                    
                    if "âœ…" in upload_result:
                        processed_count += 1
                    
                except Exception as e:
                    logger.warning(f"å›¾ç‰‡å¤„ç†å¤±è´¥ {image_id}: {e}")
                    continue
            
            return processed_count
            
        except Exception as e:
            logger.warning(f"å›¾ç‰‡RAGå¤„ç†å¤±è´¥: {e}")
            return 0
    
    def _generate_intelligent_document(self, generation_request: str, project_name: str, output_format: str) -> Dict[str, Any]:
        """ç”Ÿæˆæ™ºèƒ½æ–‡æ¡£"""
        try:
            # è¿™é‡Œå¯ä»¥è°ƒç”¨å¢å¼ºç‰ˆæ–‡æ¡£ç”Ÿæˆå™¨
            # æˆ–è€…å®ç°ç®€åŒ–ç‰ˆçš„æ–‡æ¡£ç”Ÿæˆé€»è¾‘
            
            # æ¨¡æ‹Ÿæ–‡æ¡£ç”Ÿæˆï¼ˆå®é™…åº”è¯¥è°ƒç”¨çœŸå®çš„ç”Ÿæˆå™¨ï¼‰
            doc_result = {
                "status": "success",
                "message": "æ™ºèƒ½æ–‡æ¡£ç”Ÿæˆå®Œæˆ",
                "output": {
                    "document_path": f"generated_documents/æ™ºèƒ½æ–‡æ¡£_{project_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{output_format}",
                    "format": output_format,
                    "generation_request": generation_request,
                    "project_name": project_name
                }
            }
            
            return doc_result
            
        except Exception as e:
            return {
                "status": "error",
                "message": f"æ–‡æ¡£ç”Ÿæˆå¤±è´¥: {str(e)}"
            }
    
    def _discover_pdf_files(self, directory: str) -> List[str]:
        """å‘ç°ç›®å½•ä¸­çš„PDFæ–‡ä»¶"""
        pdf_files = []
        for root, dirs, files in os.walk(directory):
            for file in files:
                if file.lower().endswith('.pdf'):
                    pdf_files.append(os.path.join(root, file))
        return pdf_files
    
    def _detect_project_name(self, pdf_source: str, pdf_files: List[str]) -> str:
        """æ™ºèƒ½æ£€æµ‹é¡¹ç›®åç§°"""
        if os.path.isfile(pdf_source):
            # å•æ–‡ä»¶ï¼šä½¿ç”¨æ–‡ä»¶å
            return os.path.splitext(os.path.basename(pdf_source))[0]
        else:
            # ç›®å½•ï¼šä½¿ç”¨ç›®å½•å
            return os.path.basename(pdf_source.rstrip('/\\'))
    
    def _extract_text_intelligently(self, content_data: Dict) -> str:
        """æ™ºèƒ½æå–æ–‡æœ¬å†…å®¹"""
        text_parts = []
        
        # å¤šç§ç»“æ„çš„æ™ºèƒ½è¯†åˆ«
        if "chapters" in content_data:
            for chapter in content_data["chapters"]:
                if "title" in chapter:
                    text_parts.append(f"# {chapter['title']}")
                if "content" in chapter:
                    text_parts.append(chapter["content"])
                if "key_points" in chapter:
                    for point in chapter["key_points"]:
                        text_parts.append(f"- {point}")
        elif "sections" in content_data:
            for section in content_data["sections"]:
                if "title" in section:
                    text_parts.append(f"## {section['title']}")
                if "content" in section:
                    text_parts.append(section["content"])
        elif "content" in content_data:
            text_parts.append(content_data["content"])
        else:
            # é€šç”¨æ–‡æœ¬æå–
            for key, value in content_data.items():
                if isinstance(value, str) and len(value) > 20:
                    text_parts.append(f"{key}: {value}")
        
        return "\n\n".join(text_parts)
    
    def _generate_smart_description(self, image_info: Dict, filename: str, project_name: str) -> str:
        """æ™ºèƒ½ç”Ÿæˆå›¾ç‰‡æè¿°"""
        description_parts = []
        
        # é¡¹ç›®ä¸Šä¸‹æ–‡
        if project_name:
            description_parts.append(f"{project_name}é¡¹ç›®ç›¸å…³å›¾ç‰‡")
        
        # æ–‡ä»¶ä¿¡æ¯
        description_parts.append(f"æ–‡ä»¶: {filename}")
        
        # ä½ç½®ä¿¡æ¯
        if "page" in image_info:
            description_parts.append(f"ç¬¬{image_info['page']}é¡µ")
        
        # å†…å®¹ç±»å‹æ¨æ–­
        if "table" in filename.lower() or "è¡¨æ ¼" in image_info.get("description", ""):
            description_parts.append("è¡¨æ ¼å†…å®¹")
        elif "chart" in filename.lower() or "å›¾è¡¨" in image_info.get("description", ""):
            description_parts.append("å›¾è¡¨æ•°æ®")
        elif "diagram" in filename.lower() or "ç¤ºæ„å›¾" in image_info.get("description", ""):
            description_parts.append("ç¤ºæ„å›¾")
        else:
            description_parts.append("å›¾å½¢å†…å®¹")
        
        return ", ".join(description_parts)
    
    def _cleanup_temporary_files(self, output_dir: str, content_file: str, images_file: str):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        try:
            # å¯ä»¥é€‰æ‹©æ€§ä¿ç•™æˆ–åˆ é™¤è§£æè¾“å‡º
            # è¿™é‡Œåªæ¸…ç†çœŸæ­£çš„ä¸´æ—¶æ–‡ä»¶
            temp_files = [f for f in os.listdir(output_dir) if f.endswith('.tmp')]
            for temp_file in temp_files:
                os.remove(os.path.join(output_dir, temp_file))
        except Exception as e:
            logger.warning(f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
    
    def _intelligent_batch_processing(self, pdf_directory: str, project_name: str = "") -> str:
        """æ™ºèƒ½æ‰¹é‡å¤„ç†"""
        return self._build_knowledge_base(pdf_directory, project_name)
    
    def get_usage_guide(self) -> str:
        """è·å–ä½¿ç”¨æŒ‡å—"""
        return """
ğŸ¤– æ™ºèƒ½PDFå¤„ç†å™¨ä½¿ç”¨æŒ‡å—

ğŸ¯ è®¾è®¡ç†å¿µï¼š
è®©ä¸»agenté€šè¿‡æœ€å°‘çš„å‚æ•°è‡ªåŠ¨å®ŒæˆPDFâ†’RAGâ†’æ–‡æ¡£ç”Ÿæˆçš„å®Œæ•´æµç¨‹

ğŸ“‹ åŸºæœ¬ç”¨æ³•ï¼š

1. ã€ä»…æ„å»ºçŸ¥è¯†åº“ã€‘- æœ€å¸¸ç”¨
   intelligent_pdf_processor(
       pdf_source="path/to/document.pdf",
       task_type="knowledge_base"
   )

2. ã€å®Œæ•´æµç¨‹ï¼šPDFâ†’çŸ¥è¯†åº“â†’æ–‡æ¡£ç”Ÿæˆã€‘
   intelligent_pdf_processor(
       pdf_source="path/to/document.pdf", 
       task_type="document_generation",
       generation_request="ç”ŸæˆæŠ€æœ¯æŠ¥å‘Š"
   )

3. ã€æ‰¹é‡å¤„ç†æ•´ä¸ªç›®å½•ã€‘
   intelligent_pdf_processor(
       pdf_source="path/to/pdf_directory/",
       task_type="batch_processing"
   )

ğŸ”§ å‚æ•°è¯´æ˜ï¼š
- pdf_source: PDFæ–‡ä»¶è·¯å¾„æˆ–ç›®å½•è·¯å¾„ï¼ˆå¿…éœ€ï¼‰
- task_type: ä»»åŠ¡ç±»å‹ï¼ˆknowledge_base/document_generation/batch_processingï¼‰
- generation_request: æ–‡æ¡£ç”Ÿæˆè¯·æ±‚ï¼ˆå¯é€‰ï¼‰
- project_name: é¡¹ç›®åç§°ï¼ˆå¯é€‰ï¼Œç³»ç»Ÿè‡ªåŠ¨æ£€æµ‹ï¼‰
- output_format: è¾“å‡ºæ ¼å¼ï¼ˆdocx/jsonï¼Œé»˜è®¤docxï¼‰

ğŸš€ è‡ªåŠ¨åŒ–ç‰¹æ€§ï¼š
âœ… è‡ªåŠ¨æ£€æµ‹PDFç±»å‹ï¼ˆå•æ–‡ä»¶/ç›®å½•ï¼‰
âœ… è‡ªåŠ¨é¡¹ç›®åç§°è¯†åˆ«
âœ… è‡ªåŠ¨æ–‡æœ¬embeddingåˆ°å‘é‡æ•°æ®åº“
âœ… è‡ªåŠ¨å›¾ç‰‡RAGå¤„ç†å’Œæè¿°ç”Ÿæˆ
âœ… è‡ªåŠ¨ä¸´æ—¶æ–‡ä»¶æ¸…ç†
âœ… æ™ºèƒ½é”™è¯¯å¤„ç†å’Œæ¢å¤

ğŸ’¡ ä¸»agentè°ƒç”¨ç¤ºä¾‹ï¼š
"è¯·å¤„ç†è¿™ä¸ªPDFæ–‡ä»¶å¹¶æ„å»ºçŸ¥è¯†åº“: /path/to/document.pdf"
â†’ intelligent_pdf_processor(pdf_source="/path/to/document.pdf", task_type="knowledge_base")

"åŸºäºè¿™ä¸ªPDFç”ŸæˆæŠ€æœ¯æŠ¥å‘Š: /path/to/document.pdf"  
â†’ intelligent_pdf_processor(pdf_source="/path/to/document.pdf", task_type="document_generation", generation_request="ç”ŸæˆæŠ€æœ¯æŠ¥å‘Š")

ğŸ‰ ä¸€é”®å®Œæˆæ‚¨çš„è®¾æƒ³æµç¨‹ï¼š
PDFè§£æ â†’ æ–‡æœ¬embedding â†’ å›¾ç‰‡RAG â†’ çŸ¥è¯†åº“æ„å»º âœ…
        """


# å·¥å…·å®ä¾‹åŒ–å’Œå¯¼å‡º
if __name__ == "__main__":
    processor = IntelligentPDFProcessor()
    print(processor.get_usage_guide()) 