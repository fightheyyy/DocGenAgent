#!/usr/bin/env python3
"""
PDF Embedding Service - PDFè§£æå†…å®¹çš„å‘é‡åŒ–å­˜å‚¨æœåŠ¡
å¤„ç†parsed_content.jsonå’Œimages.jsonï¼Œå°†æ–‡æœ¬å’Œå›¾ç‰‡è¿›è¡Œembeddingå¹¶å­˜å‚¨åˆ°ç»Ÿä¸€é›†åˆ
"""

import json
import os
import hashlib
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from pathlib import Path
import uuid

# å¯¼å…¥torchæ£€æŸ¥
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("âš ï¸ PyTorchä¸å¯ç”¨ï¼ŒæŸäº›é«˜çº§åŠŸèƒ½å¯èƒ½å—é™")

try:
    import chromadb
    from chromadb.config import Settings
    CHROMADB_AVAILABLE = True
except ImportError:
    CHROMADB_AVAILABLE = False
    print("âš ï¸ ChromaDBä¸å¯ç”¨ï¼Œè¯·å®‰è£…: pip install chromadb")

# å°è¯•å¯¼å…¥OpenRouterå®¢æˆ·ç«¯ç”¨äºå›¾ç‰‡æè¿°
try:
    from src.openrouter_client import OpenRouterClient
    OPENROUTER_CLIENT_AVAILABLE = True
except ImportError:
    OPENROUTER_CLIENT_AVAILABLE = False
    print("âš ï¸ OpenRouterå®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œå›¾ç‰‡VLMæè¿°åŠŸèƒ½å—é™")

# å°è¯•å¯¼å…¥MinIOå®¢æˆ·ç«¯
try:
    from minio import Minio
    MINIO_AVAILABLE = True
except ImportError:
    MINIO_AVAILABLE = False
    print("âš ï¸ MinIOå®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œå›¾ç‰‡ä¸Šä¼ åŠŸèƒ½å—é™")

class PDFEmbeddingService:
    """PDFå†…å®¹å‘é‡åŒ–æœåŠ¡ - ç»Ÿä¸€å­˜å‚¨æ–‡æœ¬å’Œå›¾ç‰‡"""
    
    def __init__(self, 
                 model_name: str = "BAAI/bge-m3", 
                 chroma_db_path: str = "rag_storage",
                 collection_name: str = "documents",
                 enable_vlm_description: bool = True,
                 enable_minio_upload: bool = True,
                 minio_endpoint: str = "43.139.19.144:9000",
                 minio_access_key: str = "minioadmin",
                 minio_secret_key: str = "minioadmin",
                 minio_bucket: str = "images",
                 minio_secure: bool = False):
        """
        åˆå§‹åŒ–PDFåµŒå…¥æœåŠ¡
        
        Args:
            model_name: BGE-M3æ¨¡å‹åç§°
            chroma_db_path: ChromaDBå­˜å‚¨è·¯å¾„
            collection_name: é›†åˆåç§°ï¼Œç»Ÿä¸€ä¸º"documents"
            enable_vlm_description: æ˜¯å¦å¯ç”¨VLMå›¾ç‰‡æè¿°åŠŸèƒ½
            enable_minio_upload: æ˜¯å¦å¯ç”¨MinIOä¸Šä¼ åŠŸèƒ½
            minio_endpoint: MinIOæœåŠ¡ç«¯ç‚¹
            minio_access_key: MinIOè®¿é—®å¯†é’¥
            minio_secret_key: MinIOå¯†é’¥
            minio_bucket: MinIOå­˜å‚¨æ¡¶åç§°
            minio_secure: æ˜¯å¦ä½¿ç”¨HTTPS
        """
        self.model_name = model_name
        self.chroma_db_path = chroma_db_path
        self.collection_name = collection_name
        self.enable_vlm_description = enable_vlm_description
        self.device = "cuda" if TORCH_AVAILABLE and torch.cuda.is_available() else "cpu"
        self.model = None
        
        # MinIOé…ç½®
        self.enable_minio_upload = enable_minio_upload
        self.minio_endpoint = minio_endpoint
        self.minio_access_key = minio_access_key
        self.minio_secret_key = minio_secret_key
        self.minio_bucket = minio_bucket
        self.minio_secure = minio_secure
        
        # åˆå§‹åŒ–VLMå®¢æˆ·ç«¯
        self.vlm_client = None
        if self.enable_vlm_description and OPENROUTER_CLIENT_AVAILABLE:
            try:
                self.vlm_client = OpenRouterClient()
                print("âœ… VLMå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œå°†å¯¹å›¾ç‰‡è¿›è¡Œæ·±åº¦æè¿°")
            except Exception as e:
                print(f"âš ï¸ VLMå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # åˆå§‹åŒ–MinIOå®¢æˆ·ç«¯
        self.minio_client = None
        if self.enable_minio_upload and MINIO_AVAILABLE:
            try:
                self.minio_client = Minio(
                    self.minio_endpoint,
                    access_key=self.minio_access_key,
                    secret_key=self.minio_secret_key,
                    secure=self.minio_secure
                )
                # æ£€æŸ¥å¹¶åˆ›å»ºå­˜å‚¨æ¡¶
                if not self.minio_client.bucket_exists(self.minio_bucket):
                    self.minio_client.make_bucket(self.minio_bucket)
                print(f"âœ… MinIOå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸï¼Œå­˜å‚¨æ¡¶: {self.minio_bucket}")
            except Exception as e:
                print(f"âš ï¸ MinIOå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
                self.minio_client = None
        
        # åˆå§‹åŒ–ChromaDB
        self._init_chroma_db()
        
    def _init_chroma_db(self):
        """åˆå§‹åŒ–ChromaDBå®¢æˆ·ç«¯å’Œé›†åˆ"""
        if not CHROMADB_AVAILABLE:
            raise RuntimeError("ChromaDBä¸å¯ç”¨ï¼Œæ— æ³•åˆå§‹åŒ–embeddingæœåŠ¡")
            
        max_retries = 3
        for attempt in range(max_retries):
            try:
                # åˆ›å»ºå­˜å‚¨ç›®å½•
                os.makedirs(self.chroma_db_path, exist_ok=True)
                
                # åˆå§‹åŒ–ChromaDBå®¢æˆ·ç«¯ - æ·»åŠ æ›´å¤šè®¾ç½®æ¥é¿å…å†²çª
                self.chroma_client = chromadb.PersistentClient(
                    path=self.chroma_db_path,
                    settings=Settings(
                        anonymized_telemetry=False,
                        allow_reset=True,
                        is_persistent=True
                    )
                )
                
                # è·å–æˆ–åˆ›å»ºç»Ÿä¸€é›†åˆ
                self.collection = self.chroma_client.get_or_create_collection(
                    name=self.collection_name,
                    metadata={"description": "PDFæ–‡æœ¬å’Œå›¾ç‰‡å†…å®¹ç»Ÿä¸€å‘é‡åŒ–å­˜å‚¨"}
                )
                
                print(f"âœ… ChromaDBåˆå§‹åŒ–æˆåŠŸ: {self.chroma_db_path}")
                print(f"ğŸ“Š ä½¿ç”¨ç»Ÿä¸€é›†åˆ: {self.collection_name}")
                return
                
            except Exception as e:
                error_msg = str(e)
                if "already exists" in error_msg and "different settings" in error_msg:
                    print(f"âš ï¸ ChromaDBå®ä¾‹å†²çªï¼Œå°è¯•é‡ç½®... (å°è¯• {attempt + 1}/{max_retries})")
                    
                    # å°è¯•é‡ç½®ChromaDBè¿æ¥
                    try:
                        if hasattr(self, 'chroma_client') and self.chroma_client:
                            self.chroma_client.reset()
                    except:
                        pass
                    
                    # ç­‰å¾…ä¸€ä¸‹å†é‡è¯•
                    import time
                    time.sleep(1)
                    
                    if attempt == max_retries - 1:
                        # æœ€åä¸€æ¬¡å°è¯•ï¼šåˆ é™¤å¹¶é‡æ–°åˆ›å»º
                        try:
                            import shutil
                            if os.path.exists(self.chroma_db_path):
                                print(f"ğŸ”„ æ¸…ç†ChromaDBç›®å½•: {self.chroma_db_path}")
                                shutil.rmtree(self.chroma_db_path)
                                os.makedirs(self.chroma_db_path, exist_ok=True)
                        except Exception as cleanup_error:
                            print(f"âš ï¸ æ¸…ç†å¤±è´¥: {cleanup_error}")
                else:
                    print(f"âŒ ChromaDBåˆå§‹åŒ–å¤±è´¥: {e}")
                    if attempt == max_retries - 1:
                        raise
                    else:
                        import time
                        time.sleep(1)
        
        # å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†
        raise RuntimeError("ChromaDBåˆå§‹åŒ–å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
    
    def _upload_to_minio(self, file_path: str, object_name: str = None) -> Optional[str]:
        """
        ä¸Šä¼ æ–‡ä»¶åˆ°MinIOå¹¶è¿”å›å…¬å…±URL
        
        Args:
            file_path: æœ¬åœ°æ–‡ä»¶è·¯å¾„
            object_name: MinIOä¸­çš„å¯¹è±¡åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨æ–‡ä»¶å
            
        Returns:
            Optional[str]: å…¬å…±URLï¼Œå¤±è´¥æ—¶è¿”å›None
        """
        if not self.minio_client or not os.path.exists(file_path):
            return None
        
        try:
            # ç”Ÿæˆå¯¹è±¡åç§°
            if object_name is None:
                # ä½¿ç”¨æ—¶é—´æˆ³å’ŒåŸæ–‡ä»¶åç”Ÿæˆå”¯ä¸€å¯¹è±¡å
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = os.path.basename(file_path)
                name, ext = os.path.splitext(filename)
                object_name = f"{timestamp}_{uuid.uuid4().hex[:8]}_{name}{ext}"
            
            # ä¸Šä¼ æ–‡ä»¶
            self.minio_client.fput_object(
                self.minio_bucket,
                object_name,
                file_path
            )
            
            # æ„é€ å…¬å…±URL
            if self.minio_secure:
                protocol = "https"
            else:
                protocol = "http"
            
            public_url = f"{protocol}://{self.minio_endpoint}/{self.minio_bucket}/{object_name}"
            
            print(f"âœ… æ–‡ä»¶ä¸Šä¼ åˆ°MinIOæˆåŠŸ: {object_name}")
            return public_url
            
        except Exception as e:
            print(f"âŒ MinIOä¸Šä¼ å¤±è´¥: {e}")
            return None
    
    def embed_parsed_pdf(self, 
                        parsed_content_path: str, 
                        images_json_path: str,
                        parser_output_dir: str) -> Dict:
        """
        å¯¹è§£æåçš„PDFå†…å®¹è¿›è¡Œembedding
        
        Args:
            parsed_content_path: parsed_content.jsonæ–‡ä»¶è·¯å¾„
            images_json_path: images.jsonæ–‡ä»¶è·¯å¾„  
            parser_output_dir: è§£æå™¨è¾“å‡ºç›®å½•
            
        Returns:
            Dict: embeddingç»“æœç»Ÿè®¡
        """
        stats = {
            "text_embeddings": 0,
            "image_embeddings": 0,
            "table_embeddings": 0,
            "total_embeddings": 0,
            "errors": []
        }
        
        try:
            # è·å–æºæ–‡ä»¶ä¿¡æ¯
            source_file, title = self._get_source_info(parsed_content_path)
            
            # å‡†å¤‡æ‰¹é‡æ•°æ®
            documents = []
            metadatas = []
            ids = []
            
            # 1. å¤„ç†æ–‡æœ¬å†…å®¹
            if os.path.exists(parsed_content_path):
                text_docs, text_metas, text_ids = self._prepare_text_embeddings(
                    parsed_content_path, source_file, title, parser_output_dir
                )
                documents.extend(text_docs)
                metadatas.extend(text_metas)
                ids.extend(text_ids)
                stats["text_embeddings"] = len(text_docs)
                
                if text_docs:
                    print(f"âœ… å‡†å¤‡æ–‡æœ¬embedding: {len(text_docs)}ä¸ªsection")
            else:
                stats["errors"].append(f"æ–‡æœ¬æ–‡ä»¶ä¸å­˜åœ¨: {parsed_content_path}")
            
            # 2. å¤„ç†å›¾ç‰‡å†…å®¹
            if os.path.exists(images_json_path):
                image_docs, image_metas, image_ids = self._prepare_image_embeddings(
                    images_json_path, source_file, title, parser_output_dir
                )
                documents.extend(image_docs)
                metadatas.extend(image_metas)
                ids.extend(image_ids)
                stats["image_embeddings"] = len(image_docs)
                
                if image_docs:
                    print(f"âœ… å‡†å¤‡å›¾ç‰‡embedding: {len(image_docs)}ä¸ªå›¾ç‰‡")
            else:
                stats["errors"].append(f"å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨: {images_json_path}")
            
            # 3. å¤„ç†è¡¨æ ¼å†…å®¹
            tables_json_path = os.path.join(parser_output_dir, "tables.json")
            if os.path.exists(tables_json_path):
                table_docs, table_metas, table_ids = self._prepare_table_embeddings(
                    tables_json_path, source_file, title, parser_output_dir
                )
                documents.extend(table_docs)
                metadatas.extend(table_metas)
                ids.extend(table_ids)
                stats["table_embeddings"] = len(table_docs)
                
                if table_docs:
                    print(f"âœ… å‡†å¤‡è¡¨æ ¼embedding: {len(table_docs)}ä¸ªè¡¨æ ¼")
            else:
                stats["errors"].append(f"è¡¨æ ¼æ–‡ä»¶ä¸å­˜åœ¨: {tables_json_path}")
            
            # 4. æ‰¹é‡æ·»åŠ åˆ°ChromaDB
            if documents:
                self.collection.add(
                    documents=documents,
                    metadatas=metadatas,
                    ids=ids
                )
                stats["total_embeddings"] = len(documents)
                print(f"âœ… æ‰¹é‡embeddingå®Œæˆ: {len(documents)}ä¸ªé¡¹ç›®")
            else:
                stats["errors"].append("æ²¡æœ‰æ‰¾åˆ°å¯åµŒå…¥çš„å†…å®¹")
                
        except Exception as e:
            error_msg = f"PDF embeddingå¤±è´¥: {e}"
            stats["errors"].append(error_msg)
            print(f"âŒ {error_msg}")
            
        return stats
    
    def _get_source_info(self, parsed_content_path: str) -> Tuple[str, str]:
        """è·å–æºæ–‡ä»¶ä¿¡æ¯"""
        source_file = "unknown"
        title = "unknown"
        
        try:
            if os.path.exists(parsed_content_path):
                with open(parsed_content_path, 'r', encoding='utf-8') as f:
                    content_data = json.load(f)
                    metadata_info = content_data.get("metadata", {})
                    source_file = metadata_info.get("source_file", "unknown")
                    title = metadata_info.get("title", "unknown")
                    
                    # ä¿®å¤æ–‡ä»¶åç¼–ç é—®é¢˜
                    source_file = self._fix_filename_encoding(source_file)
                    title = self._fix_filename_encoding(title)
                    
        except Exception as e:
            print(f"âš ï¸ è·å–æºæ–‡ä»¶ä¿¡æ¯å¤±è´¥: {e}")
            
        return source_file, title
    
    def embed_and_store_text(self, text_chunks: List[str], 
                            source_document: str = "unknown",
                            document_type: str = "Text",
                            metadatas: Optional[List[Dict]] = None,
                            project_name: Optional[str] = None) -> Dict:
        """
        å…¼å®¹æ€§æ–¹æ³•ï¼šå°†æ–‡æœ¬å—åµŒå…¥å¹¶å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“
        
        Args:
            text_chunks: æ–‡æœ¬å—åˆ—è¡¨
            source_document: æºæ–‡æ¡£åç§°
            document_type: æ–‡æ¡£ç±»å‹
            metadatas: å…ƒæ•°æ®åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            Dict: åŒ…å«åµŒå…¥ç»“æœçš„å­—å…¸
        """
        if not text_chunks:
            return {"chunks_count": 0, "collection_name": self.collection_name}
        
        try:
            # æå–é¡¹ç›®åç§°ï¼ˆå¦‚æœæ²¡æœ‰æä¾›ï¼‰
            if project_name is None:
                project_name = self._extract_project_name(source_document)
            
            # å‡†å¤‡æ–‡æ¡£å’Œå…ƒæ•°æ®
            documents = text_chunks
            if metadatas:
                # å¦‚æœæä¾›äº†å…ƒæ•°æ®ï¼Œä½¿ç”¨å®ƒä»¬ï¼Œä½†ç¡®ä¿åŒ…å«project_name
                processed_metadatas = []
                for metadata in metadatas:
                    enhanced_metadata = metadata.copy()
                    if "project_name" not in enhanced_metadata:
                        enhanced_metadata["project_name"] = project_name
                    processed_metadatas.append(enhanced_metadata)
            else:
                # å¦åˆ™åˆ›å»ºé»˜è®¤å…ƒæ•°æ®
                processed_metadatas = []
                for i, text in enumerate(text_chunks):
                    metadata = {
                        "source_file": source_document,
                        "document_type": document_type,
                        "project_name": project_name,  # ğŸ†• é¡¹ç›®éš”ç¦»å­—æ®µ
                        "chunk_index": i,
                        "content_type": "text" if document_type == "Text" else "image",
                        "embedding_time": datetime.now().isoformat(),
                        "content_length": len(text)
                    }
                    processed_metadatas.append(metadata)
            
            # ç”Ÿæˆå”¯ä¸€ID
            ids = []
            for i, text in enumerate(text_chunks):
                chunk_id = f"{source_document}_{document_type}_{i}_{hashlib.md5(text.encode()).hexdigest()[:8]}"
                ids.append(chunk_id)
            
            # æ·»åŠ åˆ°ChromaDB
            self.collection.add(
                documents=documents,
                metadatas=processed_metadatas,
                ids=ids
            )
            
            print(f"âœ… æˆåŠŸåµŒå…¥ {len(text_chunks)} ä¸ªæ–‡æœ¬å—åˆ° {self.collection_name}")
            return {
                "chunks_count": len(text_chunks),
                "collection_name": self.collection_name,
                "status": "success"
            }
            
        except Exception as e:
            print(f"âŒ æ–‡æœ¬åµŒå…¥å¤±è´¥: {e}")
            return {
                "chunks_count": 0,
                "collection_name": self.collection_name,
                "status": "error",
                "error": str(e)
            }
    
    def _extract_project_name(self, source_file: str) -> str:
        """
        ä»æºæ–‡ä»¶åä¸­æå–é¡¹ç›®åç§°
        
        Args:
            source_file: æºæ–‡ä»¶è·¯å¾„æˆ–åç§°
            
        Returns:
            str: æå–çš„é¡¹ç›®åç§°
        """
        if not source_file or source_file == "unknown":
            return "default"
            
        # è·å–æ–‡ä»¶åï¼ˆå»æ‰è·¯å¾„ï¼‰
        filename = os.path.basename(source_file)
        
        # å»æ‰æ–‡ä»¶æ‰©å±•å
        name_without_ext = os.path.splitext(filename)[0]
        
        # å¸¸è§çš„é¡¹ç›®åç§°æå–æ¨¡å¼
        project_patterns = [
            # 1. ç›´æ¥åŒ…å«é¡¹ç›®å…³é”®è¯çš„æ–‡ä»¶å
            r'([^_\-\s]+(?:å®—ç¥ |å¯ºåº™|å¤å»º|æ–‡ç‰©|ä¿æŠ¤|ä¿®ç¼®|è®¾è®¡|æ–¹æ¡ˆ))',
            r'([^_\-\s]+(?:æ‘|é•‡|å¿|å¸‚|åŒº))',
            
            # 2. ä»¥ç‰¹å®šåˆ†éš”ç¬¦åˆ†å‰²çš„ç¬¬ä¸€éƒ¨åˆ†
            r'^([^_\-\s]+)',
            
            # 3. ä¸­æ–‡é¡¹ç›®åç§°æ¨¡å¼
            r'([\u4e00-\u9fff]{2,8}(?:å®—ç¥ |å¯ºåº™|å¤å»º|æ–‡ç‰©))',
            
            # 4. å¦‚æœåŒ…å«"åˆ˜æ°å®—ç¥ "ç­‰å…·ä½“åç§°
            r'(åˆ˜æ°å®—ç¥ |æ¬§æ‘åˆ˜æ°å®—ç¥ )',
        ]
        
        import re
        
        # æŒ‰ä¼˜å…ˆçº§å°è¯•ä¸åŒçš„æå–æ¨¡å¼
        for pattern in project_patterns:
            match = re.search(pattern, name_without_ext)
            if match:
                project_name = match.group(1).strip()
                # æ¸…ç†é¡¹ç›®åç§°
                project_name = re.sub(r'[^\u4e00-\u9fff\w]', '', project_name)
                if len(project_name) >= 2:  # è‡³å°‘2ä¸ªå­—ç¬¦
                    return project_name
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°æ¨¡å¼ï¼Œä½¿ç”¨æ–‡ä»¶åçš„å‰å‡ ä¸ªå­—ç¬¦
        clean_name = re.sub(r'[^\u4e00-\u9fff\w]', '', name_without_ext)
        if len(clean_name) >= 2:
            # å–å‰4-8ä¸ªå­—ç¬¦ä½œä¸ºé¡¹ç›®å
            return clean_name[:min(8, len(clean_name))]
        
        # æœ€åå›é€€æ–¹æ¡ˆ
        return "default"
    
    def _fix_filename_encoding(self, filename: str) -> str:
        """ä¿®å¤æ–‡ä»¶åç¼–ç é—®é¢˜"""
        if not filename or filename == "unknown":
            return filename
            
        try:
            # å°è¯•ä¿®å¤URLç¼–ç çš„ä¸­æ–‡å­—ç¬¦
            import urllib.parse
            # å…ˆå°è¯•URLè§£ç 
            try:
                decoded = urllib.parse.unquote(filename, encoding='utf-8')
                if decoded != filename:
                    filename = decoded
            except:
                pass
            
            # å¤„ç†å¸¸è§çš„ç¼–ç é—®é¢˜
            # å¦‚æœåŒ…å«ç‰¹æ®Šç¼–ç å­—ç¬¦ï¼Œå°è¯•é‡æ–°ç¼–ç 
            if 'Ã¥' in filename or 'Ã§' in filename or 'Ã¨' in filename:
                try:
                    # å°è¯•ä»latin-1è§£ç ä¸ºutf-8
                    fixed = filename.encode('latin-1').decode('utf-8')
                    filename = fixed
                except:
                    # å¦‚æœå¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
                    try:
                        # å°è¯•ä»gbkè§£ç 
                        fixed = filename.encode('latin-1').decode('gbk')
                        filename = fixed
                    except:
                        pass
            
            # æå–æ–‡ä»¶åï¼ˆå»æ‰è·¯å¾„ï¼‰
            filename = os.path.basename(filename)
            
            # å¦‚æœæ–‡ä»¶åä»ç„¶åŒ…å«ä¹±ç ï¼Œå°è¯•ä»æ–‡ä»¶è·¯å¾„ä¸­æå–
            if any(char in filename for char in ['Ã¥', 'Ã§', 'Ã¨', 'Ã£', 'Ã¢']):
                # å°è¯•ä½¿ç”¨æ—¶é—´æˆ³ä½œä¸ºæ ‡è¯†
                import re
                timestamp_match = re.search(r'(\d{13})', filename)
                if timestamp_match:
                    timestamp = timestamp_match.group(1)
                    # å°è¯•æ‰¾åˆ°PDFæ‰©å±•å
                    if '.pdf' in filename.lower():
                        filename = f"æ–‡æ¡£_{timestamp}.pdf"
                    else:
                        filename = f"æ–‡æ¡£_{timestamp}"
                else:
                    # å¦‚æœæ²¡æœ‰æ—¶é—´æˆ³ï¼Œä½¿ç”¨é€šç”¨åç§°
                    if '.pdf' in filename.lower():
                        filename = "PDFæ–‡æ¡£.pdf"
                    else:
                        filename = "PDFæ–‡æ¡£"
            
        except Exception as e:
            print(f"âš ï¸ ä¿®å¤æ–‡ä»¶åç¼–ç å¤±è´¥: {e}")
            # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œä½¿ç”¨é€šç”¨åç§°
            filename = "PDFæ–‡æ¡£"
            
        return filename
    
    def _prepare_text_embeddings(self, parsed_content_path: str, source_file: str, 
                                title: str, parser_output_dir: str) -> Tuple[List[str], List[Dict], List[str]]:
        """å‡†å¤‡æ–‡æœ¬å†…å®¹çš„embeddingæ•°æ®"""
        documents = []
        metadatas = []
        ids = []
        
        try:
            # æå–é¡¹ç›®åç§°
            project_name = self._extract_project_name(source_file)
            print(f"ğŸ“‹ æ–‡æœ¬å†…å®¹é¡¹ç›®åç§°: {project_name}")
            
            # è¯»å–è§£æå†…å®¹
            with open(parsed_content_path, 'r', encoding='utf-8') as f:
                content_data = json.load(f)
            
            # å¤„ç†æ¯ä¸ªsection
            sections = content_data.get("sections", [])
            
            for i, section in enumerate(sections):
                content = section.get("content", "").strip()
                if not content:
                    continue
                    
                # ç”Ÿæˆå”¯ä¸€ID
                section_id = self._generate_id(source_file, "text", i, content)
                
                # æ„å»ºå…ƒæ•°æ® - æ·»åŠ é¡¹ç›®åç§°
                section_metadata = {
                    "source_file": source_file,
                    "document_title": title,
                    "content_type": "text",  # å…³é”®å­—æ®µï¼šåŒºåˆ†æ–‡æœ¬å’Œå›¾ç‰‡
                    "project_name": project_name,  # ğŸ†• é¡¹ç›®éš”ç¦»å­—æ®µ
                    "section_index": i,
                    "source_page": section.get("source_page", i),
                    "content_length": len(content),
                    "embedding_time": datetime.now().isoformat(),
                    "parser_output_path": parser_output_dir
                }
                
                documents.append(content)
                metadatas.append(section_metadata)
                ids.append(section_id)
                
        except Exception as e:
            print(f"âŒ æ–‡æœ¬embeddingå‡†å¤‡å¤±è´¥: {e}")
            
        return documents, metadatas, ids
    
    def _prepare_image_embeddings(self, images_json_path: str, source_file: str,
                                 title: str, parser_output_dir: str) -> Tuple[List[str], List[Dict], List[str]]:
        """å‡†å¤‡å›¾ç‰‡å†…å®¹çš„embeddingæ•°æ® - æ”¯æŒVLMæ·±åº¦åˆ†æ"""
        documents = []
        metadatas = []
        ids = []
        
        try:
            # æå–é¡¹ç›®åç§°
            project_name = self._extract_project_name(source_file)
            print(f"ğŸ“¸ å›¾ç‰‡å†…å®¹é¡¹ç›®åç§°: {project_name}")
            
            # è¯»å–å›¾ç‰‡ä¿¡æ¯
            with open(images_json_path, 'r', encoding='utf-8') as f:
                images_data = json.load(f)
            
            print(f"ğŸ“¸ å¤„ç† {len(images_data)} å¼ å›¾ç‰‡ï¼ŒVLMæè¿°å¯ç”¨: {self.enable_vlm_description}")
            
            for image_id, image_info in images_data.items():
                # è·å–åŸºæœ¬ä¿¡æ¯
                caption = image_info.get("caption", f"å›¾ç‰‡ {image_id}")
                # [å·²ç§»é™¤] context = image_info.get("context", "") - ä¸å†ä½¿ç”¨contextå­—æ®µ
                image_path = image_info.get("image_path", "")
                
                # æ„å»ºå®Œæ•´çš„å›¾ç‰‡è·¯å¾„
                if image_path and not os.path.isabs(image_path):
                    full_image_path = os.path.join(parser_output_dir, image_path)
                else:
                    full_image_path = image_path
                
                # å°è¯•é€šè¿‡VLMç”Ÿæˆæ·±åº¦æè¿°
                image_description = self._generate_image_description(
                    full_image_path, caption, image_id
                )
                
                # å¦‚æœç”Ÿæˆçš„æè¿°ä¸ºç©ºï¼Œä½¿ç”¨åŸºæœ¬ä¿¡æ¯
                if not image_description.strip():
                    image_description = f"{caption}"
                    # [å·²ç§»é™¤] ä¸å†æ·»åŠ contextä¿¡æ¯
                
                # ğŸ†• ä¸Šä¼ å›¾ç‰‡åˆ°MinIO
                minio_url = None
                if self.enable_minio_upload and os.path.exists(full_image_path):
                    # ç”Ÿæˆå¯¹è±¡åç§°ï¼šé¡¹ç›®_å›¾ç‰‡ID_åŸæ–‡ä»¶å
                    filename = os.path.basename(full_image_path)
                    name, ext = os.path.splitext(filename)
                    object_name = f"images/{source_file}_{image_id}_{name}{ext}"
                    minio_url = self._upload_to_minio(full_image_path, object_name)
                
                # ç”Ÿæˆå”¯ä¸€ID
                img_id = self._generate_id(source_file, "image", image_id, image_path)
                
                # æ„å»ºå…ƒæ•°æ® - æ·»åŠ é¡¹ç›®åç§°
                image_metadata = {
                    "source_file": source_file,
                    "document_title": title,
                    "content_type": "image",  # å…³é”®å­—æ®µï¼šåŒºåˆ†æ–‡æœ¬å’Œå›¾ç‰‡
                    "project_name": project_name,  # ğŸ†• é¡¹ç›®éš”ç¦»å­—æ®µ
                    "image_id": image_id,
                    "image_path": image_path,  # ä¿ç•™åŸå§‹æœ¬åœ°è·¯å¾„
                    "minio_url": minio_url,    # ğŸ†• æ·»åŠ MinIO URL
                    "caption": caption,
                    # [å·²ç§»é™¤] "context": context, - ä¸å†å­˜å‚¨contextå­—æ®µ
                    "vlm_description": image_description,  # ğŸ†• ä¿å­˜å®Œæ•´çš„VLMæè¿°åˆ°å…ƒæ•°æ®
                    "original_caption": caption,  # ğŸ†• ä¿å­˜åŸå§‹æ ‡é¢˜
                    "width": image_info.get("width", 0),
                    "height": image_info.get("height", 0),
                    "figure_size": image_info.get("figure_size", 0),
                    "figure_aspect": image_info.get("figure_aspect", 1.0),
                    "embedding_time": datetime.now().isoformat(),
                    "parser_output_path": parser_output_dir,
                    "vlm_description_enabled": self.enable_vlm_description,
                    "has_vlm_description": self.vlm_client is not None,
                    "vlm_success": not image_description.startswith("Error:") and len(image_description) > len(caption),  # ğŸ†• VLMæ˜¯å¦æˆåŠŸç”Ÿæˆæè¿°
                    "minio_upload_enabled": self.enable_minio_upload,
                    "has_minio_url": minio_url is not None
                }
                
                documents.append(image_description)
                metadatas.append(image_metadata)
                ids.append(img_id)
                
        except Exception as e:
            print(f"âŒ å›¾ç‰‡embeddingå‡†å¤‡å¤±è´¥: {e}")
            
        return documents, metadatas, ids
    
    def _prepare_table_embeddings(self, tables_json_path: str, source_file: str,
                                 title: str, parser_output_dir: str) -> Tuple[List[str], List[Dict], List[str]]:
        """å‡†å¤‡è¡¨æ ¼å†…å®¹çš„embeddingæ•°æ® - æ”¯æŒVLMæ·±åº¦åˆ†æ"""
        documents = []
        metadatas = []
        ids = []
        
        try:
            # æå–é¡¹ç›®åç§°
            project_name = self._extract_project_name(source_file)
            print(f"ğŸ“Š è¡¨æ ¼å†…å®¹é¡¹ç›®åç§°: {project_name}")
            
            # è¯»å–è¡¨æ ¼ä¿¡æ¯
            with open(tables_json_path, 'r', encoding='utf-8') as f:
                tables_data = json.load(f)
            
            print(f"ğŸ“Š å¤„ç† {len(tables_data)} ä¸ªè¡¨æ ¼ï¼ŒVLMæè¿°å¯ç”¨: {self.enable_vlm_description}")
            
            for table_id, table_info in tables_data.items():
                # è·å–åŸºæœ¬ä¿¡æ¯
                caption = table_info.get("caption", f"è¡¨æ ¼ {table_id}")
                table_path = table_info.get("table_path", "")
                
                # æ„å»ºå®Œæ•´çš„è¡¨æ ¼å›¾ç‰‡è·¯å¾„
                if table_path and not os.path.isabs(table_path):
                    full_table_path = os.path.join(parser_output_dir, table_path)
                else:
                    full_table_path = table_path
                
                # å°è¯•é€šè¿‡VLMç”Ÿæˆè¡¨æ ¼æè¿°
                table_description = self._generate_table_description(
                    full_table_path, caption, table_id
                )
                
                # å¦‚æœç”Ÿæˆçš„æè¿°ä¸ºç©ºï¼Œä½¿ç”¨åŸºæœ¬ä¿¡æ¯
                if not table_description.strip():
                    table_description = f"è¡¨æ ¼: {caption}"
                
                # ğŸ†• ä¸Šä¼ è¡¨æ ¼å›¾ç‰‡åˆ°MinIO
                minio_url = None
                if self.enable_minio_upload and os.path.exists(full_table_path):
                    # ç”Ÿæˆå¯¹è±¡åç§°ï¼šé¡¹ç›®_è¡¨æ ¼ID_åŸæ–‡ä»¶å
                    filename = os.path.basename(full_table_path)
                    name, ext = os.path.splitext(filename)
                    object_name = f"tables/{source_file}_{table_id}_{name}{ext}"
                    minio_url = self._upload_to_minio(full_table_path, object_name)
                
                # ç”Ÿæˆå”¯ä¸€ID
                table_id_str = self._generate_id(source_file, "table", table_id, table_path)
                
                # æ„å»ºå…ƒæ•°æ® - æ·»åŠ é¡¹ç›®åç§°
                table_metadata = {
                    "source_file": source_file,
                    "document_title": title,
                    "content_type": "table",  # å…³é”®å­—æ®µï¼šåŒºåˆ†æ–‡æœ¬ã€å›¾ç‰‡å’Œè¡¨æ ¼
                    "project_name": project_name,  # ğŸ†• é¡¹ç›®éš”ç¦»å­—æ®µ
                    "table_id": table_id,
                    "table_path": table_path,  # ä¿ç•™åŸå§‹æœ¬åœ°è·¯å¾„
                    "minio_url": minio_url,    # ğŸ†• æ·»åŠ MinIO URL
                    "caption": caption,
                    "vlm_description": table_description,  # ğŸ†• ä¿å­˜å®Œæ•´çš„VLMè¡¨æ ¼æè¿°åˆ°å…ƒæ•°æ®
                    "original_caption": caption,  # ğŸ†• ä¿å­˜åŸå§‹æ ‡é¢˜
                    "width": table_info.get("width", 0),
                    "height": table_info.get("height", 0),
                    "figure_size": table_info.get("figure_size", 0),
                    "figure_aspect": table_info.get("figure_aspect", 1.0),
                    "embedding_time": datetime.now().isoformat(),
                    "parser_output_path": parser_output_dir,
                    "vlm_description_enabled": self.enable_vlm_description,
                    "has_vlm_description": self.vlm_client is not None,
                    "vlm_success": not table_description.startswith("Error:") and len(table_description) > len(caption),  # ğŸ†• VLMæ˜¯å¦æˆåŠŸç”Ÿæˆæè¿°
                    "minio_upload_enabled": self.enable_minio_upload,
                    "has_minio_url": minio_url is not None
                }
                
                documents.append(table_description)
                metadatas.append(table_metadata)
                ids.append(table_id_str)
                
        except Exception as e:
            print(f"âŒ è¡¨æ ¼embeddingå‡†å¤‡å¤±è´¥: {e}")
            
        return documents, metadatas, ids
    
    def _generate_table_description(self, table_path: str, caption: str, table_id: str) -> str:
        """
        ç”Ÿæˆè¡¨æ ¼æè¿° - ä½¿ç”¨VLMåˆ†æè¡¨æ ¼å†…å®¹
        
        Args:
            table_path: è¡¨æ ¼å›¾ç‰‡è·¯å¾„
            caption: åŸºæœ¬æ ‡é¢˜
            table_id: è¡¨æ ¼ID
            
        Returns:
            str: è¡¨æ ¼æè¿°æ–‡æœ¬
        """
        # å¦‚æœVLMå®¢æˆ·ç«¯å¯ç”¨ä¸”è¡¨æ ¼å›¾ç‰‡å­˜åœ¨ï¼Œä½¿ç”¨VLMç”Ÿæˆæè¿°
        if self.vlm_client and os.path.exists(table_path):
            try:
                print(f"ğŸ“Š å¯¹è¡¨æ ¼ {table_id} è¿›è¡ŒVLMæ·±åº¦åˆ†æ...")
                
                # æ„å»ºä¸“é—¨é’ˆå¯¹è¡¨æ ¼çš„VLMæç¤ºè¯
                prompt = """è¯·ä½œä¸ºä¸“ä¸šçš„è¡¨æ ¼åˆ†æå¸ˆï¼Œè¯¦ç»†åˆ†æå’Œæè¿°è¿™ä¸ªè¡¨æ ¼çš„å†…å®¹ã€‚è¯·æŒ‰ä»¥ä¸‹ç»“æ„å›ç­”ï¼š

1. è¡¨æ ¼ç±»å‹ï¼šç¡®å®šè¿™æ˜¯æ•°æ®è¡¨ã€å¯¹æ¯”è¡¨ã€ç»Ÿè®¡è¡¨ã€æ—¶é—´è¡¨è¿˜æ˜¯å…¶ä»–ç±»å‹çš„è¡¨æ ¼
2. è¡¨æ ¼ç»“æ„ï¼šæè¿°è¡¨æ ¼çš„è¡Œæ•°ã€åˆ—æ•°ã€è¡¨å¤´å’Œæ•´ä½“ç»“æ„
3. æ ¸å¿ƒæ•°æ®ï¼šè¯¦ç»†åˆ—å‡ºè¡¨æ ¼ä¸­çš„å…³é”®æ•°æ®ã€æ•°å€¼å’Œä¿¡æ¯
4. æ–‡æœ¬å†…å®¹ï¼šå®Œæ•´è½¬å½•è¡¨æ ¼ä¸­çš„æ‰€æœ‰æ–‡å­—ã€æ•°å­—ã€æ ‡é¢˜ã€å•ä½ç­‰
5. æ•°æ®å…³ç³»ï¼šåˆ†æè¡¨æ ¼æ•°æ®ä¹‹é—´çš„å…³ç³»ã€è¶‹åŠ¿å’Œæ¨¡å¼
6. å…³é”®ä¿¡æ¯ï¼šæç‚¼è¡¨æ ¼è¦è¡¨è¾¾çš„æ ¸å¿ƒä¿¡æ¯å’Œç»“è®º

è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œå°½å¯èƒ½è¯¦ç»†å’Œå‡†ç¡®åœ°è½¬å½•è¡¨æ ¼å†…å®¹ã€‚"""
                
                # è°ƒç”¨VLMç”Ÿæˆæè¿°
                vlm_description = self.vlm_client.get_image_description_gemini(
                    table_path, prompt=prompt
                )
                
                # æ£€æŸ¥VLMæè¿°æ˜¯å¦æˆåŠŸ
                if vlm_description and not vlm_description.startswith("Error:"):
                    # ç»„åˆå®Œæ•´æè¿°
                    full_description = f"è¡¨æ ¼æ ‡é¢˜: {caption}\n\nè¯¦ç»†å†…å®¹: {vlm_description}"
                    
                    print(f"âœ… è¡¨æ ¼VLMæè¿°ç”ŸæˆæˆåŠŸ: {table_id}")
                    return full_description
                else:
                    print(f"âš ï¸ è¡¨æ ¼VLMæè¿°ç”Ÿæˆå¤±è´¥: {table_id}, é”™è¯¯: {vlm_description}")
                    
            except Exception as e:
                print(f"âš ï¸ è¡¨æ ¼VLMæè¿°ç”Ÿæˆå¼‚å¸¸: {table_id}, é”™è¯¯: {e}")
        
        # å¦‚æœVLMä¸å¯ç”¨æˆ–å¤±è´¥ï¼Œä½¿ç”¨åŸºæœ¬ä¿¡æ¯
        basic_description = f"è¡¨æ ¼æ ‡é¢˜: {caption}"
        
        print(f"ğŸ“ ä½¿ç”¨åŸºæœ¬æè¿°: {table_id}")
        return basic_description
    
    def _generate_image_description(self, image_path: str, caption: str, image_id: str) -> str:
        """
        ç”Ÿæˆå›¾ç‰‡æè¿° - ä¼˜å…ˆä½¿ç”¨VLMï¼Œå¤±è´¥æ—¶ä½¿ç”¨åŸºæœ¬ä¿¡æ¯
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            caption: åŸºæœ¬æ ‡é¢˜
            image_id: å›¾ç‰‡ID
            
        Returns:
            str: å›¾ç‰‡æè¿°æ–‡æœ¬
        """
        # å¦‚æœVLMå®¢æˆ·ç«¯å¯ç”¨ä¸”å›¾ç‰‡å­˜åœ¨ï¼Œä½¿ç”¨VLMç”Ÿæˆæè¿°
        if self.vlm_client and os.path.exists(image_path):
            try:
                print(f"ğŸ” å¯¹å›¾ç‰‡ {image_id} è¿›è¡ŒVLMæ·±åº¦åˆ†æ...")
                
                # æ„å»ºé’ˆå¯¹Gemini 2.5 Flashä¼˜åŒ–çš„VLMæç¤ºè¯
                prompt = """# è§’è‰²
ä½ æ˜¯ä¸€ä¸ªç²¾ç‚¼çš„å›¾åƒåˆ†æå¼•æ“ã€‚

# ä»»åŠ¡
ä¸ºç»™å®šçš„å›¾ç‰‡ç”Ÿæˆä¸€æ®µæå…¶ç²¾ç®€çš„æ ¸å¿ƒæè¿°ï¼Œè¯¥æè¿°å°†ç”¨äºè¯­ä¹‰æœç´¢ã€‚ä½ çš„ç›®æ ‡æ˜¯â€œç´¢å¼•â€å›¾ç‰‡å†…å®¹ï¼Œè€Œä¸æ˜¯â€œè§£è¯´â€å›¾ç‰‡ã€‚

# æ ¸å¿ƒè§„åˆ™
1.  **ä¸“æ³¨äºå…³é”®å…ƒç´ **ï¼šåªè¯†åˆ«å’Œæè¿°å›¾ç‰‡ä¸­æœ€æ ¸å¿ƒçš„1-3ä¸ªä¸»ä½“ã€çŠ¶æ€æˆ–æ¦‚å¿µã€‚
2.  **æå–å…³é”®è¯ï¼Œè€Œéå®Œæ•´å™è¿°**ï¼šç”Ÿæˆèƒ½å¤Ÿä»£è¡¨å›¾ç‰‡å†…å®¹çš„å…³é”®è¯ç»„åˆæˆ–çŸ­è¯­ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªæ•…äº‹æ€§çš„æ®µè½ã€‚å¤šä½¿ç”¨åè¯å’Œå…³é”®åŠ¨è¯ã€‚
3.  **ç»“æ„å»ºè®®**ï¼šå°½é‡ä½¿ç”¨â€œä¸»ä½“ + çŠ¶æ€/è¡Œä¸º + å…³é”®å¯¹è±¡â€çš„ç»“æ„ã€‚ä¾‹å¦‚ï¼Œâ€œä¸€å¼ å…³äº[ä¸»é¢˜]çš„[å›¾è¡¨ç±»å‹]â€æˆ–â€œ[ä¸»ä½“]çš„[æŸç§çŠ¶æ€]ç‰¹å†™â€ã€‚
4.  **ç»å¯¹ç®€æ´**ï¼šæè¿°é€šå¸¸åº”åœ¨15åˆ°30å­—ä¹‹é—´ã€‚å‰”é™¤æ‰€æœ‰ä¸å¿…è¦çš„ä¿®é¥°è¯å’Œå¼•å¯¼è¯­ï¼ˆä¾‹å¦‚ä¸è¦ç”¨â€œè¿™å¼ å›¾ç‰‡æ˜¾ç¤ºäº†â€¦â€ï¼‰ã€‚
5.  **å¿½ç•¥æ— å…³ä¸Šä¸‹æ–‡**ï¼šå¦‚æœå›¾ç‰‡é™„å¸¦çš„å‚è€ƒæ–‡å­—ä¸å›¾ç‰‡å†…å®¹ä¸ç¬¦ï¼Œå¿…é¡»å®Œå…¨å¿½ç•¥è¯¥æ–‡å­—ã€‚

# ç¤ºä¾‹
- **è¾“å…¥å›¾ç‰‡**: ä¸€å¼ ç®¡é“æ¥å£å¤„ä¸¥é‡ç”Ÿé”ˆçš„ç…§ç‰‡ã€‚
- **åˆæ ¼è¾“å‡º**: â€œç®¡é“æ¥å£å¤„çš„ä¸¥é‡è…èš€ä¸é‡‘å±é”ˆè¿¹ç‰¹å†™ã€‚â€
- **ä¸åˆæ ¼è¾“å‡º**: â€œè¿™å¼ å›¾ç‰‡å‘æˆ‘ä»¬å±•ç¤ºäº†ä¸€ä¸ªçœ‹èµ·æ¥å¾ˆæ—§çš„é‡‘å±ç®¡é“ï¼Œå®ƒè¿æ¥ç€å¦ä¸€ä¸ªéƒ¨åˆ†ï¼Œè¿æ¥å¤„æœ‰å¾ˆå¤šæ£•è‰²çš„é”ˆè¿¹ï¼Œå¯èƒ½æ˜¯å› ä¸ºé•¿æ—¶é—´æš´éœ²åœ¨æ½®æ¹¿ç¯å¢ƒä¸­å¯¼è‡´çš„ã€‚â€
"""
                
                # [å·²ç§»é™¤] ä¸å†æ·»åŠ contextä¿¡æ¯åˆ°VLMæç¤ºè¯
                
                # è°ƒç”¨VLMç”Ÿæˆæè¿°
                vlm_description = self.vlm_client.get_image_description_gemini(
                    image_path, prompt=prompt
                )
                
                # æ£€æŸ¥VLMæè¿°æ˜¯å¦æˆåŠŸ
                if vlm_description and not vlm_description.startswith("Error:"):
                    # ç»„åˆå®Œæ•´æè¿°
                    full_description = f"å›¾ç‰‡æ ‡é¢˜: {caption}\n\nè¯¦ç»†æè¿°: {vlm_description}"
                    # [å·²ç§»é™¤] ä¸å†æ·»åŠ contextä¿¡æ¯åˆ°VLMæè¿°
                    
                    print(f"âœ… VLMæè¿°ç”ŸæˆæˆåŠŸ: {image_id}")
                    return full_description
                else:
                    print(f"âš ï¸ VLMæè¿°ç”Ÿæˆå¤±è´¥: {image_id}, é”™è¯¯: {vlm_description}")
                    
            except Exception as e:
                print(f"âš ï¸ VLMæè¿°ç”Ÿæˆå¼‚å¸¸: {image_id}, é”™è¯¯: {e}")
        
        # å¦‚æœVLMä¸å¯ç”¨æˆ–å¤±è´¥ï¼Œä½¿ç”¨åŸºæœ¬ä¿¡æ¯
        basic_description = f"å›¾ç‰‡æ ‡é¢˜: {caption}"
        # [å·²ç§»é™¤] ä¸å†æ·»åŠ contextä¿¡æ¯åˆ°åŸºæœ¬æè¿°
        
        print(f"ğŸ“ ä½¿ç”¨åŸºæœ¬æè¿°: {image_id}")
        return basic_description
    
    def _generate_id(self, source_file: str, content_type: str, index_or_id: any, content: str) -> str:
        """ç”Ÿæˆå†…å®¹çš„å”¯ä¸€ID"""
        # ä½¿ç”¨æºæ–‡ä»¶è·¯å¾„ã€å†…å®¹ç±»å‹ã€ç´¢å¼•å’Œå†…å®¹hashç”Ÿæˆå”¯ä¸€ID
        content_hash = hashlib.md5(str(content).encode('utf-8')).hexdigest()[:8]
        file_name = os.path.basename(source_file)
        return f"{content_type}_{file_name}_{index_or_id}_{content_hash}"
    
    def search(self, query: str, 
               content_type: Optional[str] = None,
               top_k: int = 5, 
               source_file_filter: Optional[str] = None,
               project_name: Optional[str] = None) -> List[Dict]:
        """
        ç»Ÿä¸€æœç´¢æ¥å£
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            content_type: å†…å®¹ç±»å‹è¿‡æ»¤ ("text", "image", "table", Noneè¡¨ç¤ºæœç´¢å…¨éƒ¨)
            top_k: è¿”å›ç»“æœæ•°é‡
            source_file_filter: æºæ–‡ä»¶è¿‡æ»¤å™¨
            project_name: é¡¹ç›®åç§°è¿‡æ»¤å™¨ï¼ˆå®ç°é¡¹ç›®éš”ç¦»ï¼‰
            
        Returns:
            List[Dict]: æœç´¢ç»“æœ
        """
        try:
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            where_condition = {}
            
            if content_type:
                where_condition["content_type"] = content_type
                
            if source_file_filter:
                where_condition["source_file"] = source_file_filter
                
            if project_name:
                # ğŸ”§ ä¿®å¤ï¼šç¡®ä¿å®Œå…¨çš„é¡¹ç›®éš”ç¦»
                # ä¸¥æ ¼åŒ¹é…é¡¹ç›®åç§°ï¼Œåªè¿”å›æœ‰project_nameå­—æ®µä¸”å€¼åŒ¹é…çš„æ•°æ®
                if where_condition:
                    # å¦‚æœå·²æœ‰å…¶ä»–æ¡ä»¶ï¼Œä½¿ç”¨$andç»„åˆ
                    where_condition = {
                        "$and": [
                            where_condition,  # ç°æœ‰æ¡ä»¶
                            {"project_name": {"$eq": project_name}}  # ä¸¥æ ¼åŒ¹é…é¡¹ç›®åç§°
                        ]
                    }
                else:
                    # å¦‚æœæ²¡æœ‰å…¶ä»–æ¡ä»¶ï¼Œç›´æ¥ä½¿ç”¨é¡¹ç›®æ¡ä»¶
                    where_condition = {"project_name": {"$eq": project_name}}
                print(f"ğŸ” ä¸¥æ ¼é™å®šé¡¹ç›®èŒƒå›´: {project_name}")
            
            # æ‰§è¡Œæœç´¢
            results = self.collection.query(
                query_texts=[query],
                n_results=top_k,
                where=where_condition if where_condition else None
            )
            
            # æ ¼å¼åŒ–ç»“æœ
            formatted_results = []
            if results["documents"] and results["documents"][0]:
                for i in range(len(results["documents"][0])):
                    result = {
                        "content": results["documents"][0][i],
                        "metadata": results["metadatas"][0][i],
                        "distance": results["distances"][0][i] if results["distances"] else None,
                        "id": results["ids"][0][i],
                        "content_type": results["metadatas"][0][i].get("content_type", "unknown")
                    }
                    formatted_results.append(result)
            
            return formatted_results
            
        except Exception as e:
            print(f"âŒ æœç´¢å¤±è´¥: {e}")
            return []
    
    def search_similar_content(self, query: str, 
                              content_type: Optional[str] = None,
                              top_k: int = 5, 
                              source_file_filter: Optional[str] = None,
                              project_name: Optional[str] = None) -> List[Dict]:
        """
        æœç´¢ç›¸ä¼¼å†…å®¹ - searchæ–¹æ³•çš„å‹å¥½æ¥å£
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            content_type: å†…å®¹ç±»å‹è¿‡æ»¤ ("text", "image", "table", Noneè¡¨ç¤ºæœç´¢å…¨éƒ¨)
            top_k: è¿”å›ç»“æœæ•°é‡
            source_file_filter: æºæ–‡ä»¶è¿‡æ»¤å™¨
            project_name: é¡¹ç›®åç§°è¿‡æ»¤å™¨ï¼ˆå®ç°é¡¹ç›®éš”ç¦»ï¼‰
            
        Returns:
            List[Dict]: æœç´¢ç»“æœï¼Œæ¯ä¸ªç»“æœåŒ…å«å†…å®¹ã€å…ƒæ•°æ®å’Œç›¸ä¼¼åº¦
        """
        # è°ƒç”¨åŸå§‹searchæ–¹æ³•
        results = self.search(query, content_type, top_k, source_file_filter, project_name)
        
        # è½¬æ¢distanceä¸ºsimilarity (distanceè¶Šå°ï¼Œç›¸ä¼¼åº¦è¶Šé«˜)
        for result in results:
            if result.get("distance") is not None:
                # å°†distanceè½¬æ¢ä¸ºsimilarity (0-1ä¹‹é—´ï¼Œ1è¡¨ç¤ºå®Œå…¨ç›¸ä¼¼)
                result["similarity"] = 1 / (1 + result["distance"])
            else:
                result["similarity"] = 0
                
            # æ·»åŠ ä¸€äº›ç”¨æˆ·å‹å¥½çš„å­—æ®µ
            metadata = result.get("metadata", {})
            result["document_type"] = metadata.get("content_type", "unknown")
            result["source_document"] = metadata.get("source_file", "unknown")
            result["document_title"] = metadata.get("document_title", "unknown")
            
        return results
    
    def search_text_only(self, query: str, top_k: int = 5, source_file_filter: Optional[str] = None, project_name: Optional[str] = None) -> List[Dict]:
        """
        åªæœç´¢æ–‡æœ¬å†…å®¹
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            top_k: è¿”å›ç»“æœæ•°é‡
            source_file_filter: æºæ–‡ä»¶è¿‡æ»¤å™¨
            project_name: é¡¹ç›®åç§°è¿‡æ»¤å™¨ï¼ˆå®ç°é¡¹ç›®éš”ç¦»ï¼‰
            
        Returns:
            List[Dict]: æœç´¢ç»“æœ
        """
        return self.search(query, content_type="text", top_k=top_k, source_file_filter=source_file_filter, project_name=project_name)
    
    def search_images_only(self, query: str, top_k: int = 5, source_file_filter: Optional[str] = None, project_name: Optional[str] = None) -> List[Dict]:
        """
        åªæœç´¢å›¾ç‰‡å†…å®¹
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            top_k: è¿”å›ç»“æœæ•°é‡
            source_file_filter: æºæ–‡ä»¶è¿‡æ»¤å™¨
            project_name: é¡¹ç›®åç§°è¿‡æ»¤å™¨ï¼ˆå®ç°é¡¹ç›®éš”ç¦»ï¼‰
            
        Returns:
            List[Dict]: æœç´¢ç»“æœ
        """
        return self.search(query, content_type="image", top_k=top_k, source_file_filter=source_file_filter, project_name=project_name)
    
    def search_tables_only(self, query: str, top_k: int = 5, source_file_filter: Optional[str] = None, project_name: Optional[str] = None) -> List[Dict]:
        """
        åªæœç´¢è¡¨æ ¼å†…å®¹
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            top_k: è¿”å›ç»“æœæ•°é‡
            source_file_filter: æºæ–‡ä»¶è¿‡æ»¤å™¨
            project_name: é¡¹ç›®åç§°è¿‡æ»¤å™¨ï¼ˆå®ç°é¡¹ç›®éš”ç¦»ï¼‰
            
        Returns:
            List[Dict]: æœç´¢ç»“æœ
        """
        return self.search(query, content_type="table", top_k=top_k, source_file_filter=source_file_filter, project_name=project_name)
    
    def search_by_project(self, query: str, project_name: str, top_k: int = 5, content_type: Optional[str] = None) -> List[Dict]:
        """
        æŒ‰é¡¹ç›®æœç´¢ - é¡¹ç›®éš”ç¦»çš„ä¸“ç”¨æ¥å£
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            project_name: é¡¹ç›®åç§°ï¼ˆå¿…å¡«ï¼‰
            top_k: è¿”å›ç»“æœæ•°é‡
            content_type: å†…å®¹ç±»å‹è¿‡æ»¤ ("text", "image", "table", Noneè¡¨ç¤ºæœç´¢å…¨éƒ¨)
            
        Returns:
            List[Dict]: æœç´¢ç»“æœ
        """
        print(f"ğŸ¢ é¡¹ç›®é™å®šæœç´¢: '{project_name}' - æŸ¥è¯¢: '{query}'")
        return self.search(query, content_type=content_type, top_k=top_k, project_name=project_name)
    
    def get_available_projects(self) -> List[str]:
        """
        è·å–æ‰€æœ‰å¯ç”¨çš„é¡¹ç›®åç§°
        
        Returns:
            List[str]: é¡¹ç›®åç§°åˆ—è¡¨
        """
        try:
            # è·å–æ‰€æœ‰å…ƒæ•°æ®
            all_results = self.collection.get()
            
            # æå–æ‰€æœ‰é¡¹ç›®åç§°
            projects = set()
            for metadata in all_results["metadatas"]:
                project_name = metadata.get("project_name", "default")
                projects.add(project_name)
            
            project_list = sorted(list(projects))
            print(f"ğŸ“‹ å‘ç° {len(project_list)} ä¸ªé¡¹ç›®: {', '.join(project_list)}")
            return project_list
            
        except Exception as e:
            print(f"âŒ è·å–é¡¹ç›®åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def get_project_stats(self, project_name: str) -> Dict:
        """
        è·å–ç‰¹å®šé¡¹ç›®çš„ç»Ÿè®¡ä¿¡æ¯
        
        Args:
            project_name: é¡¹ç›®åç§°
            
        Returns:
            Dict: é¡¹ç›®ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            # è·å–é¡¹ç›®çš„æ‰€æœ‰å†…å®¹ - ä½¿ç”¨ä¸¥æ ¼åŒ¹é…
            where_condition = {"project_name": {"$eq": project_name}}
            results = self.collection.get(where=where_condition)
            
            total_count = len(results["documents"])
            text_count = 0
            image_count = 0
            table_count = 0
            
            for metadata in results["metadatas"]:
                content_type = metadata.get("content_type", "unknown")
                if content_type == "text":
                    text_count += 1
                elif content_type == "image":
                    image_count += 1
                elif content_type == "table":
                    table_count += 1
            
            stats = {
                "project_name": project_name,
                "total_embeddings": total_count,
                "text_embeddings": text_count,
                "image_embeddings": image_count,
                "table_embeddings": table_count,
                "collection_name": self.collection_name
            }
            
            print(f"ğŸ“Š é¡¹ç›® '{project_name}' ç»Ÿè®¡: æ€»è®¡{total_count}æ¡ (æ–‡æœ¬{text_count}, å›¾ç‰‡{image_count}, è¡¨æ ¼{table_count})")
            return stats
            
        except Exception as e:
            print(f"âŒ è·å–é¡¹ç›®ç»Ÿè®¡å¤±è´¥: {e}")
            return {"project_name": project_name, "error": str(e)}
    
    def migrate_legacy_data(self) -> Dict:
        """
        è¿ç§»è€æ•°æ®ï¼Œä¸ºæ²¡æœ‰project_nameå­—æ®µçš„æ•°æ®æ·»åŠ é¡¹ç›®åç§°
        
        Returns:
            Dict: è¿ç§»ç»“æœç»Ÿè®¡
        """
        try:
            print("ğŸ”„ å¼€å§‹è¿ç§»è€æ•°æ®ï¼Œä¸ºç¼ºå°‘project_nameçš„æ•°æ®æ·»åŠ é¡¹ç›®åç§°...")
            
            # è·å–æ‰€æœ‰æ•°æ®
            all_results = self.collection.get()
            
            migrated_count = 0
            total_count = len(all_results["documents"])
            
            print(f"ğŸ“Š æ‰¾åˆ° {total_count} æ¡æ•°æ®ï¼Œæ£€æŸ¥å“ªäº›éœ€è¦è¿ç§»...")
            
            # æ‰¹é‡æ›´æ–°æ²¡æœ‰project_nameçš„æ•°æ®
            ids_to_update = []
            metadatas_to_update = []
            
            for i, metadata in enumerate(all_results["metadatas"]):
                doc_id = all_results["ids"][i]
                
                # å¦‚æœæ²¡æœ‰project_nameå­—æ®µï¼Œæ·»åŠ å®ƒ
                if "project_name" not in metadata:
                    source_file = metadata.get("source_file", "unknown")
                    project_name = self._extract_project_name(source_file)
                    
                    # æ›´æ–°å…ƒæ•°æ®
                    updated_metadata = metadata.copy()
                    updated_metadata["project_name"] = project_name
                    
                    ids_to_update.append(doc_id)
                    metadatas_to_update.append(updated_metadata)
                    migrated_count += 1
                    
                    if migrated_count <= 5:  # åªæ˜¾ç¤ºå‰5ä¸ªç¤ºä¾‹
                        print(f"  ğŸ“„ {source_file} â†’ é¡¹ç›®: {project_name}")
            
            # æ‰§è¡Œæ‰¹é‡æ›´æ–°
            if ids_to_update:
                print(f"\nğŸ”„ æ­£åœ¨æ›´æ–° {len(ids_to_update)} æ¡æ•°æ®...")
                self.collection.update(
                    ids=ids_to_update,
                    metadatas=metadatas_to_update
                )
                print(f"âœ… æ•°æ®è¿ç§»å®Œæˆ!")
            else:
                print("â„¹ï¸ æ‰€æœ‰æ•°æ®éƒ½å·²åŒ…å«project_nameå­—æ®µï¼Œæ— éœ€è¿ç§»")
            
            # è¿”å›è¿ç§»ç»Ÿè®¡
            result = {
                "total_documents": total_count,
                "migrated_documents": migrated_count,
                "status": "success",
                "message": f"æˆåŠŸè¿ç§» {migrated_count}/{total_count} æ¡æ•°æ®"
            }
            
            print(f"\nğŸ“‹ è¿ç§»ç»“æœ: {result['message']}")
            return result
            
        except Exception as e:
            error_msg = f"æ•°æ®è¿ç§»å¤±è´¥: {e}"
            print(f"âŒ {error_msg}")
            return {
                "status": "error",
                "error": error_msg,
                "migrated_documents": 0
            }
    
    def get_legacy_data_stats(self) -> Dict:
        """
        è·å–è€æ•°æ®ç»Ÿè®¡ï¼ˆæ²¡æœ‰project_nameå­—æ®µçš„æ•°æ®ï¼‰
        
        Returns:
            Dict: è€æ•°æ®ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            # è·å–æ‰€æœ‰æ•°æ®
            all_results = self.collection.get()
            
            total_count = len(all_results["documents"])
            legacy_count = 0
            projects_with_data = {}
            
            for metadata in all_results["metadatas"]:
                if "project_name" not in metadata:
                    legacy_count += 1
                    # ç»Ÿè®¡æ¥æºæ–‡ä»¶
                    source_file = metadata.get("source_file", "unknown")
                    if source_file not in projects_with_data:
                        projects_with_data[source_file] = 0
                    projects_with_data[source_file] += 1
            
            stats = {
                "total_documents": total_count,
                "legacy_documents": legacy_count,
                "modern_documents": total_count - legacy_count,
                "legacy_files": list(projects_with_data.keys()),
                "legacy_file_stats": projects_with_data
            }
            
            print(f"ğŸ“Š è€æ•°æ®ç»Ÿè®¡: {legacy_count}/{total_count} æ¡æ•°æ®ç¼ºå°‘project_nameå­—æ®µ")
            if projects_with_data:
                print("ğŸ“ æ¶‰åŠçš„æ–‡ä»¶:")
                for file, count in list(projects_with_data.items())[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                    print(f"  - {file}: {count} æ¡")
                if len(projects_with_data) > 5:
                    print(f"  - ... è¿˜æœ‰ {len(projects_with_data) - 5} ä¸ªæ–‡ä»¶")
            
            return stats
            
        except Exception as e:
            print(f"âŒ è·å–è€æ•°æ®ç»Ÿè®¡å¤±è´¥: {e}")
            return {"error": str(e)}
    
    def search_by_filename(self, filename: str, top_k: int = 10) -> List[Dict]:
        """
        æŒ‰æ–‡ä»¶åæœç´¢æ‰€æœ‰å†…å®¹
        
        Args:
            filename: æ–‡ä»¶åï¼ˆæ”¯æŒéƒ¨åˆ†åŒ¹é…ï¼‰
            top_k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            List[Dict]: æœç´¢ç»“æœ
        """
        try:
            # ä½¿ç”¨whereæ¡ä»¶è¿‡æ»¤æ–‡ä»¶å
            where_condition = {
                "source_file": {
                    "$contains": filename
                }
            }
            
            # æ‰§è¡Œæœç´¢ï¼ˆä½¿ç”¨ç©ºæŸ¥è¯¢è·å–æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶ï¼‰
            results = self.collection.query(
                query_texts=[""],  # ç©ºæŸ¥è¯¢
                n_results=top_k,
                where=where_condition
            )
            
            # æ ¼å¼åŒ–ç»“æœ
            formatted_results = []
            if results["documents"] and results["documents"][0]:
                for i, doc in enumerate(results["documents"][0]):
                    metadata = results["metadatas"][0][i]
                    formatted_result = {
                        "content": doc[:200] + "..." if len(doc) > 200 else doc,
                        "metadata": metadata,
                        "distance": results["distances"][0][i] if results["distances"] and results["distances"][0] else 0.0,
                        "content_type": metadata.get("content_type", "unknown"),
                        "source_file": metadata.get("source_file", "unknown")
                    }
                    formatted_results.append(formatted_result)
            
            return formatted_results
            
        except Exception as e:
            print(f"âŒ æŒ‰æ–‡ä»¶åæœç´¢å¤±è´¥: {e}")
            return []
    
    def get_collection_stats(self) -> Dict:
        """è·å–é›†åˆç»Ÿè®¡ä¿¡æ¯"""
        try:
            total_count = self.collection.count()
            
            # è·å–æŒ‰å†…å®¹ç±»å‹åˆ†ç»„çš„ç»Ÿè®¡
            stats = {
                "total_embeddings": total_count,
                "collection_name": self.collection_name
            }
            
            # å°è¯•è·å–åˆ†ç±»ç»Ÿè®¡ï¼ˆå¦‚æœé›†åˆä¸ä¸ºç©ºï¼‰
            if total_count > 0:
                try:
                    # è·å–æ‰€æœ‰å…ƒæ•°æ®æ¥ç»Ÿè®¡ç±»å‹åˆ†å¸ƒ
                    all_results = self.collection.get()
                    
                    text_count = 0
                    image_count = 0
                    table_count = 0
                    
                    for metadata in all_results["metadatas"]:
                        content_type = metadata.get("content_type", "unknown")
                        if content_type == "text":
                            text_count += 1
                        elif content_type == "image":
                            image_count += 1
                        elif content_type == "table":
                            table_count += 1
                    
                    stats["text_embeddings"] = text_count
                    stats["image_embeddings"] = image_count
                    stats["table_embeddings"] = table_count
                    
                except Exception as e:
                    print(f"âš ï¸ è·å–è¯¦ç»†ç»Ÿè®¡å¤±è´¥: {e}")
                    stats["text_embeddings"] = "unknown"
                    stats["image_embeddings"] = "unknown"
                    stats["table_embeddings"] = "unknown"
            else:
                stats["text_embeddings"] = 0
                stats["image_embeddings"] = 0
                stats["table_embeddings"] = 0
            
            return stats
            
        except Exception as e:
            print(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {"error": str(e)} 