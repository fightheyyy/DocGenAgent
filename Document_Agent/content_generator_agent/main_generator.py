#!/usr/bin/env python3
"""
ç®€åŒ–æ–‡æ¡£ç”Ÿæˆå™¨ - ä¸»ç¨‹åº

åŠŸèƒ½ï¼š
- è¯»å–JSONæ–‡ä»¶ï¼ˆç”Ÿæˆæ–‡æ¡£çš„ä¾æ®.jsonï¼‰
- æ”¯æŒç»Ÿä¸€çš„å¹¶å‘ç®¡ç†
- åªç”Ÿæˆæ­£æ–‡å†…å®¹ï¼ˆä¸åŒ…å«æ ‡é¢˜ï¼‰
- è¾“å‡ºå®Œæ•´ç‰ˆmarkdownæ–‡æ¡£ï¼ˆæ— é¦–è¡Œç¼©è¿›ï¼‰
"""

import json
import os
import sys
import time
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Any, Tuple
from datetime import datetime
import logging

# ç¡®ä¿å¯ä»¥å¯¼å…¥æ¨¡å—
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from .simple_agent import SimpleContentGeneratorAgent
from clients.openrouter_client import OpenRouterClient
from config.settings import setup_logging, get_concurrency_manager, ConcurrencyManager


class MainDocumentGenerator:
    """ä¸»æ–‡æ¡£ç”Ÿæˆå™¨ - æ”¯æŒç»Ÿä¸€çš„å¹¶å‘ç®¡ç†"""
    
    def __init__(self, concurrency_manager: ConcurrencyManager = None):
        # è®¾ç½®æ—¥å¿—
        setup_logging()
        self.logger = logging.getLogger(f"{__name__}.{self.__class__.__name__}")
        
        # åˆå§‹åŒ–LLMå®¢æˆ·ç«¯å’ŒAgent
        self.llm_client = OpenRouterClient()
        self.agent = SimpleContentGeneratorAgent(self.llm_client)
        
        # å¹¶å‘ç®¡ç†å™¨
        self.concurrency_manager = concurrency_manager or get_concurrency_manager()
        self.max_workers = self.concurrency_manager.get_max_workers('content_generator_agent')
        self.rate_limit_delay = self.concurrency_manager.get_rate_limit_delay()
        
        # é€Ÿç‡æ§åˆ¶
        self.last_request_time = 0
        self.request_lock = threading.Lock()
        
        self.logger.info(f"MainDocumentGenerator åˆå§‹åŒ–å®Œæˆï¼Œå¹¶å‘çº¿ç¨‹æ•°: {self.max_workers}, é€Ÿç‡é™åˆ¶: {self.rate_limit_delay}ç§’")

    def set_max_workers(self, max_workers: int):
        """åŠ¨æ€è®¾ç½®æœ€å¤§çº¿ç¨‹æ•°"""
        self.max_workers = max_workers
        self.concurrency_manager.set_max_workers('content_generator_agent', max_workers)
        self.logger.info(f"ContentGeneratorAgent çº¿ç¨‹æ•°å·²æ›´æ–°ä¸º: {max_workers}")

    def get_max_workers(self) -> int:
        """è·å–å½“å‰æœ€å¤§çº¿ç¨‹æ•°"""
        return self.max_workers

    def set_rate_limit_delay(self, delay: float):
        """åŠ¨æ€è®¾ç½®é€Ÿç‡é™åˆ¶å»¶è¿Ÿ"""
        self.rate_limit_delay = delay
        self.concurrency_manager.set_rate_limit_delay(delay)
        self.logger.info(f"ContentGeneratorAgent é€Ÿç‡é™åˆ¶å·²æ›´æ–°ä¸º: {delay}ç§’")

    def get_rate_limit_delay(self) -> float:
        """è·å–å½“å‰é€Ÿç‡é™åˆ¶å»¶è¿Ÿ"""
        return self.rate_limit_delay

    def generate_document(self, json_file_path: str = "ç¬¬äºŒagentçš„è¾“å‡º_åˆ˜æ°å®—ç¥ _rag.json") -> str:
        """
        ç”Ÿæˆæ–‡æ¡£
        
        Args:
            json_file_path: JSONæ–‡ä»¶è·¯å¾„
            
        Returns:
            str: å®Œæ•´ç‰ˆæ–‡æ¡£è·¯å¾„
        """
        
        print("ğŸš€ å¼€å§‹ç”Ÿæˆæ–‡æ¡£...")
        print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {json_file_path}")
        print(f"ğŸ”§ å¹¶è¡Œçº¿ç¨‹: {self.max_workers}")
        print(f"â±ï¸  é€Ÿç‡é™åˆ¶: {self.rate_limit_delay}ç§’/è¯·æ±‚")
        print("=" * 60)
        
        # 1. æ£€æŸ¥æ–‡ä»¶
        if not os.path.exists(json_file_path):
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {json_file_path}")
        
        # 2. è¯»å–JSON
        with open(json_file_path, 'r', encoding='utf-8') as f:
            json_data = json.load(f)
        
        # 3. å¹¶è¡Œç”Ÿæˆå†…å®¹
        updated_json = self._generate_content_parallel(json_data)
        
        # 4. ä¿å­˜JSONå’Œç”Ÿæˆmarkdown
        return self._save_results(updated_json)
    
    def _generate_content_parallel(self, json_data: Dict[str, Any]) -> Dict[str, Any]:
        """å¹¶è¡Œç”Ÿæˆå†…å®¹"""
        
        print("âš¡ å¼€å§‹å¹¶è¡Œç”Ÿæˆ...")
        
        updated_json = json_data.copy()
        report_guide = updated_json.get('report_guide', [])
        
        # å‡†å¤‡ä»»åŠ¡åˆ—è¡¨
        tasks = []
        for title_idx, title_section in enumerate(report_guide):
            sections = title_section.get('sections', [])
            for section_idx, section in enumerate(sections):
                task = {
                    'title_idx': title_idx,
                    'section_idx': section_idx,
                    'subtitle': section.get('subtitle', ''),
                    'how_to_write': section.get('how_to_write', ''),
                    'retrieved_data': section.get('retrieved_data', ''),
                    'title': title_section.get('title', '')
                }
                tasks.append(task)
        
        total_tasks = len(tasks)
        completed_tasks = 0
        
        print(f"ğŸ“‹ æ€»ä»»åŠ¡æ•°: {total_tasks}")
        
        # å¹¶è¡Œæ‰§è¡Œ
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_task = {
                executor.submit(self._generate_single_section, task): task
                for task in tasks
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_task):
                task = future_to_task[future]
                try:
                    result = future.result()
                    
                    # æ›´æ–°JSON
                    title_idx = task['title_idx']
                    section_idx = task['section_idx']
                    section = updated_json['report_guide'][title_idx]['sections'][section_idx]
                    
                    section['generated_content'] = result['content']
                    section['quality_score'] = result['quality_score']
                    section['word_count'] = result['word_count']
                    section['generation_time'] = result['generation_time']
                    
                    completed_tasks += 1
                    progress = (completed_tasks / total_tasks) * 100
                    
                    print(f"âœ… [{completed_tasks:2d}/{total_tasks}] {progress:5.1f}% | {task['subtitle'][:20]:<20} | {result['word_count']:4d}å­— | è´¨é‡:{result['quality_score']:.2f}")
                    
                except Exception as e:
                    completed_tasks += 1
                    print(f"âŒ [{completed_tasks:2d}/{total_tasks}] å¤±è´¥ | {task['subtitle'][:20]:<20} | é”™è¯¯: {e}")
        
        print("ğŸ‰ å¹¶è¡Œç”Ÿæˆå®Œæˆ!")
        return updated_json
    
    def _generate_single_section(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå•ä¸ªç« èŠ‚ï¼ˆå¸¦é€Ÿç‡é™åˆ¶ï¼‰"""
        
        # é€Ÿç‡é™åˆ¶
        with self.request_lock:
            current_time = time.time()
            time_since_last = current_time - self.last_request_time
            
            if time_since_last < self.rate_limit_delay:
                sleep_time = self.rate_limit_delay - time_since_last
                time.sleep(sleep_time)
            
            self.last_request_time = time.time()
        
        # ç”Ÿæˆå†…å®¹
        return self.agent.generate_content_from_json(
            task['subtitle'],
            task['how_to_write'],
            task['retrieved_data']
        )
    
    def _save_results(self, updated_json: Dict[str, Any]) -> str:
        """ä¿å­˜ç»“æœæ–‡ä»¶"""
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜JSON
        json_path = f"ç”Ÿæˆæ–‡æ¡£çš„ä¾æ®_å®Œæˆ_{timestamp}.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(updated_json, f, ensure_ascii=False, indent=2)
        
        # ç”Ÿæˆmarkdown
        full_md_path = f"å®Œæ•´ç‰ˆæ–‡æ¡£_{timestamp}.md"
        
        # å®Œæ•´ç‰ˆ
        full_content = self._convert_to_markdown(updated_json)
        with open(full_md_path, 'w', encoding='utf-8') as f:
            f.write(full_content)
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = self._get_stats(updated_json)
        
        print("=" * 60)
        print("ğŸ“Š ç”Ÿæˆç»Ÿè®¡:")
        print(f"   æ€»ç« èŠ‚æ•°: {stats['total_sections']}")
        print(f"   å®Œæˆç« èŠ‚: {stats['completed_sections']}")
        print(f"   æ€»å­—æ•°: {stats['total_words']:,}")
        print(f"   å¹³å‡è´¨é‡åˆ†: {stats['average_quality']:.3f}")
        print("=" * 60)
        print("ğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"   JSON: {json_path}")
        print(f"   å®Œæ•´ç‰ˆ: {full_md_path}")
        print("=" * 60)
        
        return full_md_path
    
    def _convert_to_markdown(self, json_data: Dict[str, Any]) -> str:
        """è½¬æ¢ä¸ºmarkdownæ ¼å¼"""
        
        markdown_lines = []
        report_guide = json_data.get('report_guide', [])
        
        for title_section in report_guide:
            title = title_section.get('title', '')
            sections = title_section.get('sections', [])
            
            # æ·»åŠ ä¸»æ ‡é¢˜ï¼ˆä¸€çº§æ ‡é¢˜ï¼‰
            markdown_lines.append(f"# {title}")
            markdown_lines.append("")
            
            # å¤„ç†æ¯ä¸ªå­èŠ‚
            for section in sections:
                subtitle = section.get('subtitle', '')
                generated_content = section.get('generated_content', '')
                
                # æ·»åŠ å­æ ‡é¢˜ï¼ˆäºŒçº§æ ‡é¢˜ï¼‰
                markdown_lines.append(f"## {subtitle}")
                markdown_lines.append("")
                
                # æ·»åŠ ç”Ÿæˆçš„å†…å®¹ï¼ˆåªæœ‰æ­£æ–‡ï¼Œä¸åŒ…å«æ ‡é¢˜ï¼‰
                if generated_content:
                    # å¯¹æ­£æ–‡å†…å®¹è¿›è¡Œç¼©è¿›å¤„ç†
                    content = self._format_content(generated_content)
                    markdown_lines.append(content)
                else:
                    markdown_lines.append("*[å†…å®¹æœªç”Ÿæˆ]*")
                
                markdown_lines.append("")
        
        return "\n".join(markdown_lines)
    
    def _format_content(self, content: str) -> str:
        """å¯¹æ­£æ–‡å†…å®¹è¿›è¡Œæ ¼å¼åŒ–ï¼ˆæ— ç¼©è¿›ï¼‰"""
        
        if not content:
            return content
        
        # ç›´æ¥è¿”å›åŸå†…å®¹ï¼Œä¸è¿›è¡Œç¼©è¿›å¤„ç†
        return content
    
    def _get_stats(self, json_data: Dict[str, Any]) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        
        stats = {
            'total_sections': 0,
            'completed_sections': 0,
            'total_words': 0,
            'average_quality': 0.0
        }
        
        report_guide = json_data.get('report_guide', [])
        quality_scores = []
        
        for title_section in report_guide:
            sections = title_section.get('sections', [])
            stats['total_sections'] += len(sections)
            
            for section in sections:
                if 'generated_content' in section:
                    stats['completed_sections'] += 1
                    stats['total_words'] += section.get('word_count', 0)
                    
                    quality_score = section.get('quality_score', 0.0)
                    quality_scores.append(quality_score)
        
        if quality_scores:
            stats['average_quality'] = sum(quality_scores) / len(quality_scores)
        
        return stats


def main():
    """ä¸»å‡½æ•°"""
    
    try:
        # åˆ›å»ºç”Ÿæˆå™¨
        generator = MainDocumentGenerator()
        
        # ç”Ÿæˆæ–‡æ¡£
        full_path = generator.generate_document()
        
        print("ğŸ‰ æ–‡æ¡£ç”Ÿæˆå®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    sys.exit(main()) 